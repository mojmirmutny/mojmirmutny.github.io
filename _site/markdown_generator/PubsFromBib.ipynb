{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Publications markdown generator for academicpages\n",
    "\n",
    "Takes a set of bibtex of publications and converts them for use with [academicpages.github.io](academicpages.github.io). This is an interactive Jupyter notebook ([see more info here](http://jupyter-notebook-beginner-guide.readthedocs.io/en/latest/what_is_jupyter.html)). \n",
    "\n",
    "The core python code is also in `pubsFromBibs.py`. \n",
    "Run either from the `markdown_generator` folder after replacing updating the publist dictionary with:\n",
    "* bib file names\n",
    "* specific venue keys based on your bib file preferences\n",
    "* any specific pre-text for specific files\n",
    "* Collection Name (future feature)\n",
    "\n",
    "TODO: Make this work with other databases of citations, \n",
    "TODO: Merge this with the existing TSV parsing solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pybtex.database.input import bibtex\n",
    "import pybtex.database.input.bibtex \n",
    "from time import strptime\n",
    "import string\n",
    "import html\n",
    "import os\n",
    "import bibtexparser\n",
    "\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#todo: incorporate different collection types rather than a catch all publications, requires other changes to template\n",
    "publist = {\n",
    "    \"journal\":{\n",
    "        \"file\": \"/home/mojko/Documents/PhD_Projects/my_papers.bib\",\n",
    "        \"venuekey\" : \"journal\",\n",
    "        \"venue-pretext\" : \"\",\n",
    "        \"collection\" : {\"name\":\"publications\",\n",
    "                        \"permalink\":\"/publication/\"}\n",
    "    } \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_bibtex(filename):\n",
    "    # Open the BibTeX file\n",
    "    with open(filename) as bibtex_file:\n",
    "        # Use bibtexparser to parse the file\n",
    "        bib_database = bibtexparser.load(bibtex_file)\n",
    "        \n",
    "    # Convert to a dictionary\n",
    "    entries_dict = {}\n",
    "    for entry in bib_database.entries:\n",
    "        # Extract the ID or use a unique identifier\n",
    "        entry_id = entry['ID']\n",
    "        # Store each entry in the dictionary\n",
    "        entries_dict[entry_id] = entry\n",
    "\n",
    "    return entries_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "html_escape_table = {\n",
    "    \"&\": \"&amp;\",\n",
    "    '\"': \"&quot;\",\n",
    "    \"'\": \"&apos;\"\n",
    "    }\n",
    "\n",
    "def html_escape(text):\n",
    "    \"\"\"Produce entities within text.\"\"\"\n",
    "    return \"\".join(html_escape_table.get(c,c) for c in text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def latex_to_unicode(text):\n",
    "    # Mapping of LaTeX to Unicode\n",
    "    mappings = {\n",
    "        r\"\\\\'e\": \"é\", r\"\\\\'a\": \"á\", r\"\\\\'i\": \"í\", r\"\\\\'o\": \"ó\", r\"\\\\'u\": \"ú\",\n",
    "        r\"\\\\`e\": \"è\", r\"\\\\`a\": \"à\", r\"\\\\`i\": \"ì\", r\"\\\\`o\": \"ò\", r\"\\\\`u\": \"ù\",\n",
    "        r\"\\\\^e\": \"ê\", r\"\\\\^a\": \"â\", r\"\\\\^i\": \"î\", r\"\\\\^o\": \"ô\", r\"\\\\^u\": \"û\",\n",
    "        r'\\\\\"e': \"ë\", r'\\\\\"a': \"ä\", r'\\\\\"i': \"ï\", r'\\\\\"o': \"ö\", r'\\\\\"u': \"ü\", r\"\\\\'y\": \"ý\",\n",
    "        r\"\\\\~n\": \"ñ\", r\"\\\\c{c}\": \"ç\", r\"\\\\v{s}\": \"š\", r\"\\\\v{z}\": \"ž\",\n",
    "        r\"\\\\ae\": \"æ\", r\"\\\\oe\": \"œ\", r\"\\\\aa\": \"å\", r\"\\\\o\": \"ø\", r\"\\\\ss\": \"ß\",\n",
    "        # Adding mappings for the braces version\n",
    "        r\"\\\\'{e}\": \"é\", r\"\\\\'{a}\": \"á\", r\"\\\\'{i}\": \"í\", r\"\\\\'{o}\": \"ó\", r\"\\\\'{u}\": \"ú\", r\"\\\\'{y}\": \"ý\",r\"\\\\'{i}\": \"í\",\n",
    "        r\"\\\\`{e}\": \"è\", r\"\\\\`{a}\": \"à\", r\"\\\\`{i}\": \"ì\", r\"\\\\`{o}\": \"ò\", r\"\\\\`{u}\": \"ù\",\n",
    "        r\"\\\\^{e}\": \"ê\", r\"\\\\^{a}\": \"â\", r\"\\\\^{i}\": \"î\", r\"\\\\^{o}\": \"ô\", r\"\\\\^{u}\": \"û\",\n",
    "        r'\\\\\"{e}': \"ë\", r'\\\\\"{a}': \"ä\", r'\\\\\"{i}': \"ï\", r'\\\\\"{o}': \"ö\", r'\\\\\"{u}': \"ü\",\n",
    "    }\n",
    "\n",
    "    # Regular expression to match LaTeX special characters\n",
    "    regex = re.compile(\n",
    "        r\"\\\\['`^\\\"~]{?[a-zA-Z]}?|\\\\[cvo]['{][a-zA-Z]{1,2}['}]?|\\\\ss|\\\\[aeo]e|\\\\aa|\\\\o\"\n",
    "    )\n",
    "    \n",
    "    def replace(match):\n",
    "        # Default to the original if no mapping found\n",
    "        return mappings.get(match.group(0), match.group(0))\n",
    "    \n",
    "    return regex.sub(replace, text)\n",
    "\n",
    "\n",
    "def filter_alphabetic(input_string):\n",
    "    # Use a list comprehension to filter only alphabetic characters\n",
    "    filtered_string = ''.join([char for char in input_string if char.isalpha() or char ==' ' or char ==','])\n",
    "    return filtered_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"/home/mojko/Documents/PhD_Projects/my_papers.bib\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for pubsource in publist:\n",
    "parser = bibtex.Parser()\n",
    "#bibdata = parser.parse_file(file)\n",
    "bibdata = load_bibtex(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Mutny2018b': {'year': '2018',\n",
       "  'url': 'https://las.inf.ethz.ch/files/Mutny2018b.pdf',\n",
       "  'title': 'Efficient High Dimensional Bayesian Optimization with Additivity and Quadrature Fourier Features',\n",
       "  'month': 'December',\n",
       "  'booktitle': 'Neural and Information Processing Systems (NeurIPS)',\n",
       "  'author': \"Mutn{\\\\'y}, Mojmir and Krause, Andreas\",\n",
       "  'abstract': 'We develop an efficient and provably no-regret Bayesian optimization (BO) algorithm for optimization of black-box functions in high dimensions. We assume a generalized additive model with possibly overlapping variable groups. When the groups do not overlap, we are able to provide the first provably no-regret\\\\emph {polynomial time}(in the number of evaluations of the acquisition function) algorithm for solving high dimensional BO. To make the optimization efficient and feasible, we introduce a novel deterministic Fourier Features approximation based on numerical integration with detailed analysis for the squared exponential kernel. The error of this approximation decreases\\\\emph {exponentially} with the number of features, and allows for a precise approximation of both posterior mean and variance. In addition, the kernel matrix inversion improves in its complexity from cubic to essentially linear in the number of data points measured in basic arithmetic operations.',\n",
       "  'ENTRYTYPE': 'inproceedings',\n",
       "  'ID': 'Mutny2018b'},\n",
       " 'Mutny2018a': {'year': '2018',\n",
       "  'volume': '36',\n",
       "  'url': 'https://arxiv.org/pdf/1705.02005.pdf',\n",
       "  'title': 'Parallel Stochastic Newton Method',\n",
       "  'timestamp': '2017.07.25',\n",
       "  'pages': '405--426',\n",
       "  'owner': 'mojko',\n",
       "  'number': '3',\n",
       "  'journal': 'Journal of Computational Mathematics',\n",
       "  'file': ':Mutny2017.pdf:PDF',\n",
       "  'author': \"Mutn{\\\\'y}, Mojm{\\\\'\\\\i}r and Richt{\\\\'a}rik, Peter\",\n",
       "  'abstract': 'We propose a parallel stochastic Newton method (PSN) for minimizing unconstrained\\nsmooth convex functions. We analyze the method in the strongly convex case, and give conditions under which acceleration can be expected when compared to its serial counter-part. We show how PSN can be applied to the large quadratic function minimization in general, and empirical risk minimization problems. We demonstrate the practical efficiency of the method through numerical experiments and models of simple matrix classes.',\n",
       "  'ENTRYTYPE': 'article',\n",
       "  'ID': 'Mutny2018a'},\n",
       " 'Mutny2020': {'year': '2020',\n",
       "  'url': 'https://las.inf.ethz.ch/files/Mutny2020.pdf',\n",
       "  'title': 'Experimental Design for Optimization of Orthogonal Projection Pursuit Models',\n",
       "  'booktitle': 'Proceedings of the 34th AAAI Conference on Artificial Intelligence (AAAI)',\n",
       "  'bdsk-url-1': 'https://las.inf.ethz.ch/files/Mutny2020.pdf',\n",
       "  'author': \"Mutn{\\\\'y}, Mojm{\\\\'\\\\i}r and Kirschner, Johannes and Krause, Andreas\",\n",
       "  'abstract': 'Bayesian optimization and kernelized bandit algorithms are widely used techniques for sequential black box function optimization with applications in parameter tuning, control, robotics among many others. To be effective in high dimensional settings, previous approaches make additional assumptions, for example on low-dimensional subspaces or an additive structure. In this work, we go beyond the additivity assumption and use an orthogonal projection pursuit regression model, which strictly generalizes additive models. We present a two-stage algorithm motivated by experimental design to first decorrelate the additive components. Subsequently, the bandit optimization benefits from the statistically efficient additive model. Our method provably decorrelates the fully additive model and achieves optimal sublinear simple regret in terms of the number of function evaluations. To prove the rotation recovery, we derive novel concentration inequalities for linear regression on subspaces. In addition, we specifically address the issue of acquisition function optimization and present two domain dependent efficient algorithms. We validate the algorithm numerically on synthetic as well as real-world optimization problems.',\n",
       "  'ENTRYTYPE': 'inproceedings',\n",
       "  'ID': 'Mutny2020'},\n",
       " 'Mutny2020b': {'year': '2020',\n",
       "  'url': 'https://arxiv.org/pdf/1910.11561.pdf',\n",
       "  'title': 'Convergence Analysis of Block Coordinate Algorithms with Determinantal Sampling',\n",
       "  'booktitle': 'Proceedings of the 23rd International Conference on Artificial Intelligence and Statistics (AISTATS)',\n",
       "  'bdsk-url-1': 'https://arxiv.org/pdf/1910.11561.pdf',\n",
       "  'author': \"Mutn{\\\\'y}, Mojm{\\\\'\\\\i}r and Derezisnki, Michal and Krause, Andreas\",\n",
       "  'abstract': 'We analyze the convergence rate of the randomized Newton-like method introduced by Qu et. al. (2016) for smooth and convex objectives, which uses random coordinate blocks of a Hessian-over-approximation matrix $\\\\mathbf{M}$ instead of the true Hessian. The convergence analysis of the algorithm is challenging because of its complex dependence on the structure of $\\\\mathbf{M}$. However, we show that when the coordinate blocks are sampled with probability proportional to their determinant, the convergence rate depends solely on the eigenvalue distribution of matrix $\\\\mathbf{M}$, and has an analytically tractable form. To do so, we derive a fundamental new expectation formula for determinantal point processes. We show that determinantal sampling allows us to reason about the optimal subset size of blocks in terms of the spectrum of $\\\\mathbf{M}$. Additionally, we provide a numerical evaluation of our analysis, demonstrating cases where determinantal sampling is superior or on par with uniform sampling.',\n",
       "  'ENTRYTYPE': 'inproceedings',\n",
       "  'ID': 'Mutny2020b'},\n",
       " 'Kirschner2019b': {'year': '2019',\n",
       "  'url': 'https://las.inf.ethz.ch/files/kirschner19swissfel.pdf',\n",
       "  'title': 'Bayesian Optimization for Fast and Safe Parameter Tuning of SwissFEL',\n",
       "  'primaryclass': 'cs.LG',\n",
       "  'date-modified': '2019-10-22 11:58:27 +0000',\n",
       "  'booktitle': 'Proc. International Free-Electron Laser Conference (FEL2019)',\n",
       "  'bdsk-url-1': 'files/kirschner19swissfel.pdf',\n",
       "  'author': \"Kirschner, Johannes and Nonnenmacher, Manuel and Mutn{\\\\'y}, Mojm{\\\\'\\\\i}r and Hiller, Nicole and Adelmann, Andreas and Ischebeck, Rasmus and Krause, Andreas\",\n",
       "  'archiveprefix': 'arXiv',\n",
       "  'abstract': 'Parameter tuning is a notoriously time-consuming task in accelerator facilities. As tool for global optimization with noisy evaluations, Bayesian optimization was recently shown to outperform alternative methods. By learning a model of the underlying function using all available data, the next evaluation can be chosen carefully to find the optimum with as few steps as possible and without violating any safety constraints. However, the per-step computation time increases significantly with the number of parameters and the generality of the approach can lead to slow convergence on functions that are easier to optimize. To overcome these limitations, we divide the global problem into sequential subproblems that can be solved efficiently using safe Bayesian optimization. This allows us to trade off local and global convergence and to adapt to additional structure in the objective function. Further, we provide slice-plots of the function as user feedback during the optimization. We showcase how we use our algorithm to tune up the FEL output of SwissFEL with up to 40 parameters simultaneously, and reach convergence within reasonable tuning times in the order of 30 minutes (< 2000 steps).',\n",
       "  'ENTRYTYPE': 'inproceedings',\n",
       "  'ID': 'Kirschner2019b'},\n",
       " 'Tapia2020': {'year': '2020',\n",
       "  'volume': '7',\n",
       "  'url': 'https://www.liebertpub.com/doi/abs/10.1089/soro.2018.0162',\n",
       "  'title': 'MakeSense: Automated Sensor Design for Proprioceptive Soft Robots',\n",
       "  'publisher': 'Mary Ann Liebert, Inc., publishers 140 Huguenot Street, 3rd Floor New~{\\\\ldots}',\n",
       "  'pages': '332--345',\n",
       "  'number': '3',\n",
       "  'journal': 'Soft Robotics',\n",
       "  'author': 'Tapia, Javier and Knoop, Espen and Mutn{\\\\\\'y}, Mojm{\\\\\\'\\\\i}r and Otaduy, Miguel A and B{\\\\\"a}cher, Moritz',\n",
       "  'abstract': 'Soft robots have applications in safe human--robot interactions, manipulation of fragile objects, and locomotion in challenging and unstructured environments. In this article, we present a computational method for augmenting soft robots with proprioceptive sensing capabilities. Our method automatically computes a minimal stretch-receptive sensor network to user-provided soft robotic designs, which is optimized to perform well under a set of user-specified deformation-force pairs. The sensorized robots are able to reconstruct their full deformation state, under interaction forces. We cast our sensor design as a subselection problem, selecting a minimal set of sensors from a large set of fabricable ones, which minimizes the error when sensing specified deformation-force pairs. Unique to our approach is the use of an analytical gradient of our reconstruction performance measure with respect to selection variables. We demonstrate our technique on a bending bar and gripper example, illustrating more complex designs with a simulated tentacle.',\n",
       "  'ENTRYTYPE': 'article',\n",
       "  'ID': 'Tapia2020'},\n",
       " 'Borsos2020': {'year': '2020',\n",
       "  'url': 'https://arxiv.org/abs/2006.03875',\n",
       "  'title': 'Coresets via Bilevel Optimization for Continual Learning and Streaming',\n",
       "  'journal': 'Neural and Information Processing Systems (NeurIPS) 2020',\n",
       "  'booktitle': 'Proc. Neural Information Processing Systems (NeurIPS)',\n",
       "  'author': \"Borsos, Zal{\\\\'a}n and Mutn{\\\\'y}, Mojm{\\\\'\\\\i}r and Krause, Andreas\",\n",
       "  'abstract': 'Coresets are small data summaries that are sufficient for model training. They can be maintained online, enabling efficient handling of large data streams under resource constraints. However, existing constructions are limited to simple models such as k-means and logistic regression. In this work, we propose a novel coreset construction via cardinality-constrained bilevel optimization. We show how our framework can efficiently generate coresets for deep neural networks, and demonstrate its empirical benefits in continual learning and in streaming settings.',\n",
       "  'ENTRYTYPE': 'inproceedings',\n",
       "  'ID': 'Borsos2020'},\n",
       " 'Treven2021': {'year': '2021',\n",
       "  'url': 'https://arxiv.org/abs/2006.11022',\n",
       "  'title': 'Learning Controllers for Unstable Linear Quadratic Regulators from a Single Trajectory',\n",
       "  'journal': 'Learning for Dynamics \\\\& Controll (L4DC) 2021',\n",
       "  'booktitle': 'In proceedings of Learning for Dynamics \\\\& Control Conference',\n",
       "  'author': \"Treven, Lenart and Curi, Sebastian and Mutn{\\\\'y}, Mojm{\\\\'\\\\i}r and Krause, Andreas\",\n",
       "  'abstract': 'We present the first approach for learning--from a single trajectory--a linear quadratic regulator (LQR), even for unstable systems, without knowledge of the system dynamics and without requiring an initial stabilizing controller. Our central contribution is an efficient algorithm--\\\\emph {eXploration}--that quickly identifies a stabilizing controller. Our approach utilizes robust System Level Synthesis (SLS), and we prove that it succeeds in a constant number of iterations. Our approach can be used to initialize existing algorithms that require a stabilizing controller as input. When used in this way, it yields a method for learning LQRs from a single trajectory and even for unstable systems, while suffering at most regret.',\n",
       "  'ENTRYTYPE': 'inproceedings',\n",
       "  'ID': 'Treven2021'},\n",
       " 'Mutny2021a': {'year': '2021',\n",
       "  'url': 'http://proceedings.mlr.press/v139/mutny21a/mutny21a.pdf',\n",
       "  'title': 'No-regret Algorithms for Capturing Events in Poisson Point Processes',\n",
       "  'booktitle': 'Proc. International Conference for Machine Learning (ICML)',\n",
       "  'author': \"Mutn{\\\\'y}, Mojm{\\\\'\\\\i}r and Krause, Andreas\",\n",
       "  'abstract': 'Inhomogeneous Poisson point processes are widely used  models of event occurrences. We address \\\\emph{adaptive sensing of Poisson Point processes}, namely, maximizing the number of captured events subject to sensing costs. We encode prior assumptions on the rate function by modeling it as a member of a known \\\\emph{reproducing kernel Hilbert space} (RKHS). By partitioning the domain into separate small regions, and using heteroscedastic linear regression, we propose a tractable estimator of Poisson process rates for two feedback models: \\\\emph{count-record}, where exact locations of events are observed, and \\\\emph{histogram} feedback, where only counts of events are observed. We derive provably accurate anytime confidence estimates for our estimators for sequentially acquired Poisson count data. Using these, we formulate algorithms based on optimism that provably incur sublinear count-regret. We demonstrate the practicality of the method on problems from crime modeling, revenue maximization as well as environmental monitoring.',\n",
       "  'ENTRYTYPE': 'inproceedings',\n",
       "  'ID': 'Mutny2021a'},\n",
       " 'Kirschner2019': {'year': '2019',\n",
       "  'title': 'Adaptive and Safe Bayesian Optimization in High Dimensions via One-Dimensional Subspaces',\n",
       "  'primaryclass': 'cs.LG',\n",
       "  'eprint': '1902.03229',\n",
       "  'booktitle': 'Proc. International Conference for Machine Learning (ICML)',\n",
       "  'author': \"Kirschner, Johannes and Mutn{\\\\'y}, Mojm{\\\\'\\\\i}r and Hiller, Nicole and Ischebeck, Rasmus and Krause, Andreas\",\n",
       "  'archiveprefix': 'arXiv',\n",
       "  'abstract': 'Bayesian optimization is known to be difficult to scale to high dimensions, because the acquisition step requires solving a non-convex optimization problem in the same search space. In order to scale the method and keep its benefits, we propose an algorithm (LineBO) that restricts the problem to a sequence of iteratively chosen one-dimensional sub-problems that can be solved efficiently. We show that our algorithm converges globally and obtains a fast local rate when the function is strongly convex. Further, if the objective has an invariant subspace, our method automatically adapts to the effective dimension without changing the algorithm. When combined with the SafeOpt algorithm to solve the sub-problems, we obtain the first safe Bayesian optimization algorithm with theoretical guarantees applicable in high-dimensional settings. We evaluate our method on multiple synthetic benchmarks, where we obtain competitive performance. Further, we deploy our algorithm to optimize the beam intensity of the Swiss Free Electron Laser with up to 40 parameters while satisfying safe operation constraints.',\n",
       "  'ENTRYTYPE': 'inproceedings',\n",
       "  'ID': 'Kirschner2019'},\n",
       " 'Mutny2022': {'year': '2022',\n",
       "  'url': 'https://arxiv.org/abs/2110.11181',\n",
       "  'title': 'Sensing Cox Processes via Posterior Sampling and Positive Bases',\n",
       "  'booktitle': 'Proceedings of the 25th International Conference on Artificial Intelligence and Statistics (AISTATS)',\n",
       "  'author': \"Mutn{\\\\'y}, Mojm{\\\\'\\\\i}r and Krause, Andreas\",\n",
       "  'abstract': 'We study adaptive sensing of Cox point processes, a widely used model from spatial statistics. We introduce three tasks: maximization of captured events, search for the maximum of the intensity function and learning level sets of the intensity function. We model the intensity function as a sample from a truncated Gaussian process, represented in a specially constructed positive basis. In this basis, the positivity constraint on the intensity function has a simple form. We show how the \\\\emph{minimal description positive basis} can be adapted to the covariance kernel, to non-stationarity and make connections to common positive bases from prior works. Our adaptive sensing algorithms use Langevin dynamics and are based on posterior sampling (\\\\textsc{Cox-Thompson}) and top-two posterior sampling (\\\\textsc{Top2}) principles. With latter, the difference between samples serves as a surrogate to the uncertainty. We demonstrate the approach using examples from environmental monitoring and crime rate modeling, and compare it to the classical Bayesian experimental design approach.',\n",
       "  'ENTRYTYPE': 'inproceedings',\n",
       "  'ID': 'Mutny2022'},\n",
       " 'Nava2022': {'year': '2022',\n",
       "  'url': 'https://proceedings.mlr.press/v151/nava22a/nava22a.pdf',\n",
       "  'title': 'Diversified Sampling for Batched Bayesian Optimization with Determinantal Point Processes',\n",
       "  'eprint': '2110.11665',\n",
       "  'booktitle': 'Proceedings of the 25th International Conference on Artificial Intelligence and Statistics (AISTATS)',\n",
       "  'author': \"Nava, Elvis and Mutn{\\\\'y}, Mojm{\\\\'\\\\i}r and Krause, Andreas\",\n",
       "  'abstract': 'In this work we introduced DPP-BBO, a natural and easily applicable framework for enhancing batch diversity in BBO algorithms which works in more settings than previous diversification strategies: it is directly applicable to the continuous domain case, when due to approximation and non-standard models we are unable to compute hallucinations or confidence intervals (as in the Cox process example), or more generally when used in combination with any randomized BBO sampling scheme or arbitrary diversity kernel. Moreover, for DPP-TS we show improved theoretical guarantees and strong practical performance on simple regret.',\n",
       "  'ENTRYTYPE': 'inproceedings',\n",
       "  'ID': 'Nava2022'},\n",
       " 'Mutny2022b': {'year': '2022',\n",
       "  'url': 'https://arxiv.org/abs/2205.13627',\n",
       "  'title': 'Experimental Design of Linear Functionals in Reproducing Kernel Hilbert Spaces',\n",
       "  'month': 'November',\n",
       "  'booktitle': 'Proc. Neural Information Processing Systems (NeurIPS)',\n",
       "  'author': \"Mutn{\\\\'y}, Mojm{\\\\'\\\\i}r and Krause, Andreas\",\n",
       "  'abstract': 'Optimal experimental design seeks to determine the most informative allocation of experiments  to infer an unknown statistical quantity. In this work, we investigate optimal design of experiments for {\\\\em estimation of linear functionals in reproducing kernel Hilbert spaces (RKHSs)}. This problem has been extensively studied in the linear regression setting\\nunder an estimability condition, which allows estimating parameters without bias. We generalize this framework to RKHSs, and allow for the linear functional to be only approximately inferred, i.e., with a fixed bias. This scenario captures many important modern applications such as estimation of gradient maps, integrals and solutions to differential equations. We provide algorithms for constructing bias-aware designs for linear functionals. We derive non-asymptotic confidence sets for fixed and adaptive designs under sub-Gaussian noise, enabling us to certify estimation with bounded error with high probability.',\n",
       "  'ENTRYTYPE': 'inproceedings',\n",
       "  'ID': 'Mutny2022b'},\n",
       " 'Jourdan2021': {'year': '2021',\n",
       "  'url': 'https://proceedings.mlr.press/v132/jourdan21a.html',\n",
       "  'title': 'Efficient Pure Exploration for Combinatorial Bandits with Semi-Bandit Feedback',\n",
       "  'pdf': 'http://proceedings.mlr.press/v132/jourdan21a/jourdan21a.pdf',\n",
       "  'booktitle': 'Proceedings of the 32nd International Conference on Algorithmic Learning Theory (ALT)',\n",
       "  'author': \"Jourdan, Marc and Mutn{\\\\'y}, Mojm{\\\\'\\\\i}r and Kirschner, Johannes and Krause, Andreas\",\n",
       "  'abstract': 'Combinatorial bandits with semi-bandit feedback generalize multi-armed bandits, where the agent chooses sets of arms and observes a noisy reward for each arm contained in the chosen set. The action set satisfies a given structure such as forming a base of a matroid or a path in a graph. We focus on the pure-exploration problem of identifying the best arm with fixed confidence, as well as a more general setting, where the structure of the answer set differs from the one of the action set. Using the recently popularized game framework, we interpret this problem as a sequential zero-sum game and develop a CombGame meta-algorithm whose instances are asymptotically optimal algorithms with finite time guarantees. In addition to comparing two families of learners to instantiate our meta-algorithm, the main contribution of our work is a specific oracle efficient instance for best-arm identification with combinatorial actions. Based on a projection-free online learning algorithm for convex polytopes, it is the first computationally efficient algorithm which is asymptotically optimal and has competitive empirical performance.',\n",
       "  'ENTRYTYPE': 'inproceedings',\n",
       "  'ID': 'Jourdan2021'},\n",
       " 'Borsos2021': {'year': '2024',\n",
       "  'title': 'Data Summarization via Bilevel Optimization',\n",
       "  'primaryclass': 'cs.LG',\n",
       "  'journal': 'JMLR',\n",
       "  'eprint': '2109.12534',\n",
       "  'author': \"Borsos, Zal{\\\\'a}n and Mutn{\\\\'y}, Mojm{\\\\'\\\\i}r and Tagliasacchi, Marco and Krause, Andreas\",\n",
       "  'archiveprefix': 'arXiv',\n",
       "  'abstract': 'The increasing availability of massive data sets poses a series of challenges for machine learning. Prominent among these is the need to learn models under hardware or human resource constraints. In such resource-constrained settings, a simple yet powerful approach is to operate on small subsets of the data. Coresets are weighted subsets of the data that provide approximation guarantees for the optimization objective. However, existing coreset constructions are highly model-specific and are limited to simple models such as linear regression, logistic regression, and k-means. In this work, we propose a generic coreset construction framework that formulates the coreset selection as a cardinality-constrained bilevel optimization problem. In contrast to existing approaches, our framework does not require model-specific adaptations and applies to any twice differentiable model, including neural networks. We show the effectiveness of our framework for a wide range of models in various settings, including training non-convex models online and batch active learning.',\n",
       "  'ENTRYTYPE': 'article',\n",
       "  'ID': 'Borsos2021'},\n",
       " 'Mutny2023': {'year': '2023',\n",
       "  'url': 'https://arxiv.org/abs/2206.14332',\n",
       "  'title': 'Active Exploration via Experiment Design in Markov Chains',\n",
       "  'keywords': 'Machine Learning (cs.LG), Methodology (stat.ME), Machine Learning (stat.ML), FOS: Computer and information sciences',\n",
       "  'howpublished': 'AISTATS 2023',\n",
       "  'doi': '10.48550/ARXIV.2206.14332',\n",
       "  'copyright': 'arXiv.org perpetual, non-exclusive license',\n",
       "  'booktitle': 'Proceedings of the 26th International Conference on Artificial Intelligence and Statistics (AISTATS)',\n",
       "  'author': \"Mutn{\\\\'y}, Mojm{\\\\'\\\\i}r and Janik, Tadeusz and Krause, Andreas\",\n",
       "  'abstract': 'A key challenge in science and engineering is to design experiments to learn about some unknown quantity of interest. Classical experimental design optimally allocates the experimental budget to maximize a notion of utility (e.g., reduction in uncertainty about the unknown quantity). We consider a rich setting, where the experiments are associated with states in a {\\\\em Markov chain}, and we can only choose them by selecting a {\\\\em policy} controlling the state transitions. This problem captures important applications, from exploration in reinforcement learning to spatial monitoring tasks. We propose an algorithm -- \\\\textsc{markov-design} -- that efficiently selects policies whose measurement allocation \\\\emph{provably converges to the optimal one}. The algorithm is sequential in nature, adapting its choice of policies (experiments) informed by past measurements. In addition to our theoretical analysis, we showcase our framework on applications in ecological surveillance and pharmacology.',\n",
       "  'ENTRYTYPE': 'inproceedings',\n",
       "  'ID': 'Mutny2023'},\n",
       " 'Kirchner2022': {'year': '2022',\n",
       "  'volume': '25',\n",
       "  'url': 'https://link.aps.org/doi/10.1103/PhysRevAccelBeams.25.062802',\n",
       "  'title': 'Tuning particle accelerators with safety constraints using Bayesian optimization',\n",
       "  'publisher': 'American Physical Society',\n",
       "  'pages': '062802',\n",
       "  'numpages': '14',\n",
       "  'month': 'Jun',\n",
       "  'journal': 'Phys. Rev. Accel. Beams',\n",
       "  'issue': '6',\n",
       "  'doi': '10.1103/PhysRevAccelBeams.25.062802',\n",
       "  'author': \"Kirschner, Johannes and Mutn{\\\\'y}, Mojm{\\\\'\\\\i}r and Krause, Andreas and {Coello de Portugal}, Jaime and Hiller, Nicole and Snuverink, Jochem\",\n",
       "  'abstract': 'Tuning machine parameters of particle accelerators is a repetitive and time-consuming task that is challenging to automate. While many off-the-shelf optimization algorithms are available, in practice their use is limited because most methods do not account for safety-critical constraints in each iteration, such as loss signals or step-size limitations. One notable exception is safe Bayesian optimization, which is a data-driven tuning approach for global optimization with noisy feedback. We propose and evaluate a step-size limited variant of safe Bayesian optimization on two research facilities of the PSI:(a) the SwissFEL and (b) HIPA. We report promising experimental results on both machines, tuning up to 16 parameters subject to 224 constraints.',\n",
       "  'ENTRYTYPE': 'article',\n",
       "  'ID': 'Kirchner2022'},\n",
       " 'Prajapat2024': {'year': '2024',\n",
       "  'url': 'https://arxiv.org/abs/2307.13372',\n",
       "  'title': 'Submodular Reinforcement Learning',\n",
       "  'journal': 'ICLR 2024',\n",
       "  'author': \"Prajapat, Manish and Mutn{\\\\'y}, Mojm{\\\\'\\\\i}r and Zeilinger, Melanie N and Krause, Andreas\",\n",
       "  'abstract': 'In reinforcement learning (RL), rewards of states are typically considered additive, and following the Markov assumption, they are of states visited previously. In many important applications, such as coverage control, experiment design and informative path planning, rewards naturally have diminishing returns, i.e., their value decreases in light of similar states visited previously. To tackle this, we propose (SubRL), a paradigm which seeks to optimize more general, non-additive (and history-dependent) rewards modelled via submodular set functions which capture diminishing returns. Unfortunately, in general, even in tabular settings, we show that the resulting optimization problem is hard to approximate. On the other hand, motivated by the success of greedy algorithms in classical submodular optimization, we propose SubPO, a simple policy gradient-based algorithm for SubRL that handles non-additive rewards by greedily maximizing marginal gains. Indeed, under some assumptions on the underlying Markov Decision Process (MDP), SubPO recovers optimal constant factor approximations of submodular bandits. Moreover, we derive a natural policy gradient approach for locally optimizing SubRL instances even in large state- and action- spaces. We showcase the versatility of our approach by applying SubPO to several applications, such as biodiversity monitoring, Bayesian experiment design, informative path planning, and coverage maximization. Our results demonstrate sample efficiency, as well as scalability to high-dimensional state-action spaces.',\n",
       "  'ENTRYTYPE': 'proceedings',\n",
       "  'ID': 'Prajapat2024'},\n",
       " 'Emmenegger2023': {'year': '2023',\n",
       "  'url': 'https://arxiv.org/abs/2311.04402',\n",
       "  'title': 'Likelihood Ratio Confidence Sets for Sequential Decision Making',\n",
       "  'journal': 'NeurIPS 2023',\n",
       "  'booktitle': 'Proc. Neural Information Processing Systems (NeurIPS)',\n",
       "  'author': \"Emmenegger*, Nicolas and Mutn{\\\\'y}*, Mojm{\\\\'\\\\i}r and Krause, Andreas\",\n",
       "  'abstract': 'Certifiable, adaptive uncertainty estimates for unknown quantities are an essential ingredient of sequential decision-making algorithms. Standard approaches rely on problem-dependent concentration results and are limited to a specific combination of parameterization, noise family, and estimator. In this paper, we revisit the likelihood-based inference principle and propose to use\\\\emph {likelihood ratios} to construct\\\\emph {any-time valid} confidence sequences without requiring specialized treatment in each application scenario. Our method is especially suitable for problems with well-specified likelihoods, and the resulting sets always maintain the prescribed coverage in a model-agnostic manner. The size of the sets depends on a choice of estimator sequence in the likelihood ratio. We discuss how to provably choose the best sequence of estimators and shed light on connections to online convex optimization with algorithms such as Follow-the-Regularized-Leader. To counteract the initially large bias of the estimators, we propose a reweighting scheme that also opens up deployment in non-parametric settings such as RKHS function classes. We provide a\\\\emph {non-asymptotic} analysis of the likelihood ratio confidence sets size for generalized linear models, using insights from convex duality and online learning. We showcase the practical strength of our method on generalized linear bandit problems, survival analysis, and bandits with various additive noise distributions.',\n",
       "  'ENTRYTYPE': 'inproceedings',\n",
       "  'ID': 'Emmenegger2023'},\n",
       " 'Vornholt2024': {'year': '2024',\n",
       "  'url': 'https://www.biorxiv.org/content/10.1101/2024.02.06.579157v1.full.pdf',\n",
       "  'type': 'preprint',\n",
       "  'title': 'Enhanced Sequence-Activity Mapping and Evolution of Artificial Metalloenzymes by Active Learning',\n",
       "  'author': \"Vornholt*, Tobias and Mutn{\\\\'y}*, Mojm{\\\\'\\\\i}r and Schmidt, Gregor and Schellhaas, Christian and Tachibana, Ryo and Panke, Sven and Ward, Thomas R. and Krause, Andreas and Jeschek, Markus\",\n",
       "  'abstract': 'Tailored enzymes hold great potential to accelerate the transition to a sustainable bioeconomy. Yet, enzyme engineering remains challenging as it relies largely on serendipity and is, therefore, highly laborious and prone to failure. The efficiency and success rates of engineering campaigns may be improved substantially by applying machine learning to construct a comprehensive representation of the sequence-activity landscape from small sets of experimental data. However, it often proves challenging to reliably model a large protein sequence space while keeping the experimental effort tractable. To address this challenge, we present an integrated pipeline combining large-scale screening with active machine learning and model-guided library design. We applied this strategy to efficiently engineer an artificial metalloenzyme (ArM) catalysing a new-to-nature hydroamination reaction. By combining lab automation and next-generation sequencing, we acquired sequence-activity data for several thousand ArM variants. We then used Gaussian process regression to model the activity landscape and guide further screening rounds according to user-defined objectives. Crucial characteristics of our enhanced enzyme engineering pipeline include i) the cost-effective generation of information-rich experimental data sets, ii) the integration of an explorative round to improve the performance of the model, as well as iii) the consideration of experimental noise during modelling. Our approach led to an order-of-magnitude boost in the hit rate of screening while making efficient use of experimental resources. Smart search strategies like this should find broad utility in enzyme engineering and accelerate the development of novel biocatalysts.',\n",
       "  'ENTRYTYPE': 'misc',\n",
       "  'ID': 'Vornholt2024'},\n",
       " 'Mutny2024': {'year': '2024',\n",
       "  'title': 'Sequential Experimental Design and Optimization with Structural Assumptions: Additivity and Subspaces',\n",
       "  'journal': '(in preparation for JMLR)',\n",
       "  'author': \"Mutn{\\\\'y}, Mojm{\\\\'\\\\i}r and Krause, Andreas\",\n",
       "  'abstract': 'Experiment design in high-dimensional problems is an important practical problem in many fields of science. Without further structural assumptions, the experiment design algorithms based on reproducing kernel hilbert spaces with classical kernels suffer from curse of dimensionality. In this work we explore additional structural assumptions of additive structure or variability in low dimensional linear subspace. We present the prior works in unified framework and analyze the projection pursuit regression models in the context of experiment design, which strictly generalize additive models. We combine them with potentially non-linear effective dimension via manifold projection pursuit regression model. We contrast to other methods developed and we address practical issues such as acquisition function optimization.',\n",
       "  'ENTRYTYPE': 'article',\n",
       "  'ID': 'Mutny2024'},\n",
       " 'Bal2023': {'year': '2023',\n",
       "  'url': 'https://mojmirmutny.github.io/publication/ReALML_workshop_Protein_Design_and_Game_Theory.pdf',\n",
       "  'title': 'Optimistic Games for Combinatorial Bayesian Optimization with Applications to Protein Design',\n",
       "  'booktitle': '3rd ReALML Workshop at NeurIPS 2023',\n",
       "  'author': \"Bal, Melis {\\\\.I}layda and Sessa, Pier Giuseppe and Mutn{\\\\'y}, Mojm{\\\\'\\\\i}r and Krause, Andreas\",\n",
       "  'abstract': 'Bayesian optimization (BO) is a powerful framework to optimize black box expensive-to-evaluate functions via sequential interactions. In several important problems (e.g. drug discovery, circuit design, neural architecture search, etc.), though, such functions are defined over $\\\\textit{combinatorial and unstructured}$ spaces. This makes existing BO algorithms not feasible due to the intractable maximization of the acquisition function to find informative evaluation points. To address this issue, we propose $\\\\textbf{GameOpt}$, a novel game-theoretical approach to combinatorial BO. $\\\\textbf{GameOpt}$ establishes a cooperative game between the different optimization variables and computes informative points to be game $\\\\textit{equilibria}$ of the acquisition function. These are stable configurations from which no variable has an incentive to deviate -- analogous to local optima in continuous domains. Crucially, this allows us to efficiently break down the complexity of the combinatorial domain into individual decision sets, making $\\\\textbf{GameOpt}$ scalable to large combinatorial spaces. We demonstrate the application of $\\\\textbf{GameOpt}$ to the challenging $\\\\textit{protein design}$ problem and validate its performance on two real-world protein datasets. Each protein can take up to $20^{X}$ possible configurations, where $X$ is the length of a protein, making standard BO methods unusable. Instead, our approach iteratively selects informative protein configurations and very quickly discovers highly active protein variants compared to other baselines.',\n",
       "  'ENTRYTYPE': 'article',\n",
       "  'ID': 'Bal2023'},\n",
       " 'Folch2024transition': {'year': '2024',\n",
       "  'url': 'https://arxiv.org/abs/2402.08406',\n",
       "  'type': 'preprint',\n",
       "  'title': 'Transition Constrained Bayesian Optimization via Markov Decision Processes',\n",
       "  'primaryclass': 'cs.LG',\n",
       "  'journal': 'arXiv:2402.08406',\n",
       "  'eprint': '2402.08406',\n",
       "  'author': \"Folch, Jose Pablo and Tsay, Calvin and Lee, Robert M and Shafei, Behrang and Ormaniec, Weronika and Krause, Andreas and van der Wilk, Mark and Misener, Ruth and Mutn{\\\\'y}, Mojm{\\\\'\\\\i}r\",\n",
       "  'archiveprefix': 'arXiv',\n",
       "  'abstract': 'Bayesian optimization is a methodology to optimize black-box functions. Traditionally, it focuses on the setting where you can arbitrarily query the search space. However, many real-life problems do not offer this flexibility; in particular, the search space of the next query may depend on previous ones. Example challenges arise in the physical sciences in the form of local movement constraints, required monotonicity in certain variables, and transitions influencing the accuracy of measurements. Altogether, such transition constraints necessitate a form of planning. This work extends Bayesian optimization via the framework of Markov Decision Processes, iteratively solving a tractable linearization of our objective using reinforcement learning to obtain a policy that plans ahead over long horizons. The resulting policy is potentially history-dependent and non-Markovian. We showcase applications in chemical reactor optimization, informative path planning, machine calibration, and other synthetic examples.',\n",
       "  'ENTRYTYPE': 'misc',\n",
       "  'ID': 'Folch2024transition'},\n",
       " 'Mutny2024t': {'year': '2024',\n",
       "  'type': 'phd',\n",
       "  'title': 'Modern Adaptive Experiment Design: Machine Learning Perspective',\n",
       "  'month': 'April',\n",
       "  'howpublished': 'https://www.research-collection.ethz.ch/handle/20.500.11850/669541',\n",
       "  'author': \"Mutn{\\\\'y}, Mojm{\\\\'\\\\i}r\",\n",
       "  'abstract': \"A key challenge in science and engineering is to design experiments to learn about some unknown quantity of interest. Optimal experimental design is a branch of statistics addressing the most informative allocation of experiments in order to infer an unknown quantity of interest. In this thesis, we fundamentally revisit and extend the methods and approaches of optimal design of experiments when our unknown quantity is a member of a reproducing kernel Hilbert space (RKHS). Estimation in RKHS is a versatile, yet sample-efficient non-parametric statistical method that allows us to capture non-linear natural phenomena using the concept of a similarity also known as the kernel. The process to set up an statistical experiment design pipeline begins by establishing a mathematical model and defining the experiment's goal as a utility. We consider the available experiments and adapt to uncertain outcomes. This thesis specifically tackles adaptive experiment design, where previous experiment outcomes inform future utility design and selection strategies. We first outline a general methodology for adaptive experiment design, addressing uncertainty and combinatorial issues through relaxation techniques. We introduce a master algorithm and its linearized form based on the Frank-Wolfe algorithm, applicable to general experimental design problems. This algorithm is demonstrated in applications involving various utilities, including reward minimization and information gathering. Subsequent sections delve into the impact of structural assumptions about the unknown quantity in RKHS, such as additivity and projection pursuit structures. We analyze these models and additionally introduce novel mathematical structures in RKHS, aiming to enhance the richness and resource efficiency of experiment design. Adaptive design requires statistical estimation and confidence estimates for the unknown quantity in the presence of randomness. We thoroughly analyze this issue from a worst-case perspective, developing confidence sets for probability distributions from parametrized families. Departing from the worst-case perspective, we provide likelihood-based confidence sets for experiments with well-specified likelihood models that provide significant improvement over the worst-case analysis. Additionally, we explore complex experiment design scenarios, where the design involves executing a policy in a sequence of steps generating trajectories. We provide a tractable reformulation of this problem using Markov chains, providing examples and modifications to traditional experimental design methods. Lastly, we demonstrate the application and versatility of modern adaptive experiment design in various domains, including enzyme optimization, adaptive Poisson sensing for spatio-temporal events, learning differential equations, and classical problems related to inferring functionals of unknown quantities.\",\n",
       "  'ENTRYTYPE': 'phdthesis',\n",
       "  'ID': 'Mutny2024t'}}"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bibdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'year': '2018',\n",
       " 'url': 'https://las.inf.ethz.ch/files/Mutny2018b.pdf',\n",
       " 'title': 'Efficient High Dimensional Bayesian Optimization with Additivity and Quadrature Fourier Features',\n",
       " 'month': 'December',\n",
       " 'booktitle': 'Neural and Information Processing Systems (NeurIPS)',\n",
       " 'author': \"Mutn{\\\\'y}, Mojmir and Krause, Andreas\",\n",
       " 'abstract': 'We develop an efficient and provably no-regret Bayesian optimization (BO) algorithm for optimization of black-box functions in high dimensions. We assume a generalized additive model with possibly overlapping variable groups. When the groups do not overlap, we are able to provide the first provably no-regret\\\\emph {polynomial time}(in the number of evaluations of the acquisition function) algorithm for solving high dimensional BO. To make the optimization efficient and feasible, we introduce a novel deterministic Fourier Features approximation based on numerical integration with detailed analysis for the squared exponential kernel. The error of this approximation decreases\\\\emph {exponentially} with the number of features, and allows for a precise approximation of both posterior mean and variance. In addition, the kernel matrix inversion improves in its complexity from cubic to essentially linear in the number of data points measured in basic arithmetic operations.',\n",
       " 'ENTRYTYPE': 'inproceedings',\n",
       " 'ID': 'Mutny2018b'}"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bibdata['Mutny2018b']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-12-01\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'dict' object has no attribute 'entries'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[99], line 40\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;66;03m#Build Citation from text\u001b[39;00m\n\u001b[1;32m     38\u001b[0m citation \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 40\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m author \u001b[38;5;129;01min\u001b[39;00m \u001b[43mbibdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mentries\u001b[49m[bib_id]\u001b[38;5;241m.\u001b[39mpersons[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauthor\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m     41\u001b[0m     \u001b[38;5;28mprint\u001b[39m (author\u001b[38;5;241m.\u001b[39mfirst_names[\u001b[38;5;241m0\u001b[39m], author\u001b[38;5;241m.\u001b[39mlast_names[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m     42\u001b[0m     citation \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mauthor\u001b[38;5;241m.\u001b[39mfirst_names[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mauthor\u001b[38;5;241m.\u001b[39mlast_names[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'dict' object has no attribute 'entries'"
     ]
    }
   ],
   "source": [
    "\n",
    "#loop through the individual references in a given bibtex file\n",
    "for b in bibdata.values():\n",
    "    #reset default date\n",
    "    pub_year = \"1900\"\n",
    "    pub_month = \"01\"\n",
    "    pub_day = \"01\"\n",
    "    \n",
    "    #b = bibdata.values[bib_id].fields\n",
    "    #print (b)\n",
    "    try:\n",
    "        pub_year = f'{b[\"year\"]}'\n",
    "\n",
    "        # #todo: this hack for month and day needs some cleanup\n",
    "        if \"month\" in b.keys(): \n",
    "            if(len(b[\"month\"])<3):\n",
    "                pub_month = \"0\"+b[\"month\"]\n",
    "                pub_month = pub_month[-2:]\n",
    "            elif(b[\"month\"] not in range(12)):\n",
    "                tmnth = strptime(b[\"month\"][:3],'%b').tm_mon   \n",
    "                pub_month = \"{:02d}\".format(tmnth) \n",
    "            else:\n",
    "                pub_month = str(b[\"month\"])\n",
    "        if \"day\" in b.keys(): \n",
    "            pub_day = str(b[\"day\"])\n",
    "\n",
    "        pub_date = pub_year+\"-\"+pub_month+\"-\"+pub_day\n",
    "        print (pub_date)\n",
    "        #strip out {} as needed (some bibtex entries that maintain formatting)\n",
    "        clean_title = b[\"title\"].replace(\"{\", \"\").replace(\"}\",\"\").replace(\"\\\\\",\"\").replace(\" \",\"-\")    \n",
    "\n",
    "        url_slug = re.sub(\"\\\\[.*\\\\]|[^a-zA-Z0-9_-]\", \"\", clean_title)\n",
    "        url_slug = url_slug.replace(\"--\",\"-\")\n",
    "\n",
    "        md_filename = (str(pub_date) + \"-\" + url_slug + \".md\").replace(\"--\",\"-\")\n",
    "        html_filename = (str(pub_date) + \"-\" + url_slug).replace(\"--\",\"-\")\n",
    "\n",
    "        #Build Citation from text\n",
    "        citation = \"\"\n",
    "        \n",
    "        for author in bibdata.entries[bib_id].persons[\"author\"]:\n",
    "            print (author.first_names[0], author.last_names[0])\n",
    "            citation += f\" {author.first_names[0]} {author.last_names[0]}, \"\n",
    "            #citation += author.first_names[0]+\" \"+author.last_names[0]+\", \"\n",
    "\n",
    "            #citation title\n",
    "        citation = citation + html_escape(b[\"title\"].replace(\"{\", \"\").replace(\"}\",\"\").replace(\"\\\\\",\"\")) + \".\\\"\"\n",
    "\n",
    "        #add venue logic depending on citation type\n",
    "        if 'booktitle' in b.keys():\n",
    "            venue =b['booktitle']\n",
    "        elif 'journal' in b.keys():\n",
    "            venue =b['journal']\n",
    "        elif b['type']=='preprint':\n",
    "            venue = 'preprint'\n",
    "        elif b['type']=='phd':\n",
    "            venue = 'PhD Thesis, ETH Zurich'\n",
    "        else:\n",
    "            venue = ''\n",
    "        #venue = ''\n",
    "        #print (b)\n",
    "        citation = citation + \", \" + pub_year + \". \" + venue \n",
    "       \n",
    "        ## YAML variables\n",
    "        md = \"---\\ntitle: \\\"\"   + html_escape(b[\"title\"].replace(\"{\", \"\").replace(\"}\",\"\").replace(\"\\\\\",\"\")) + '\"\\n'\n",
    "        \n",
    "        #md += \"\"\"collection: \"\"\" +  \"publication\"\n",
    "\n",
    "        md += \"\"\"\\npermalink: \"\"\" +\"/publication/\"  + html_filename\n",
    "        \n",
    "        note = False\n",
    "        # if \"note\" in b.keys():\n",
    "        #     if len(str(b[\"note\"])) > 5:\n",
    "        #         md += \"\\nexcerpt: '\" + html_escape(b[\"note\"]) + \"'\"\n",
    "        #         note = True\n",
    "\n",
    "        md += \"\\ndate: \" + str(pub_date) \n",
    "        md += \"\\nvenue: '\" + html_escape(venue) + \"'\"\n",
    "        \n",
    "        url = False\n",
    "        if \"url\" in b.keys():\n",
    "            if len(str(b[\"url\"])) > 5:\n",
    "                md += \"\\nurl: '\" + b[\"url\"] + \"'\"\n",
    "                url = True\n",
    "\n",
    "        #md += \"\\ncitation: '\" + html_escape(citation) + \"'\"\n",
    "\n",
    "        md += \"\\n---\\n\"\n",
    "        md+=\"\\n\"+citation\n",
    "\n",
    "        if 'abstract' in b.keys():\n",
    "            md += \"\\n\\n**Abstract**: \" + b['abstract']\n",
    "        \n",
    "\n",
    "        if url:\n",
    "            md += \"\\n\\n[Full text here](\" + b[\"url\"] + \"){:target=\\\"_blank\\\"}\\n\" \n",
    "        else:\n",
    "            md += \"\\n\\nUse [Google Scholar](https://scholar.google.com/scholar?q=\"+html.escape(clean_title.replace(\"-\",\"+\"))+\"){:target=\\\"_blank\\\"} for full citation\"\n",
    "\n",
    "\n",
    "        md +=\"<!--more-->\"\n",
    "        md_filename = os.path.basename(md_filename)\n",
    "\n",
    "        with open(\"../_publications/\" + md_filename, 'w', encoding=\"utf-8\") as f:\n",
    "            f.write(md)\n",
    "        #print(f'SUCESSFULLY PARSED {bib_id}: \\\"', b[\"title\"][:60],\"...\"*(len(b['title'])>60),\"\\\"\")\n",
    "    # field may not exist for a reference\n",
    "    except KeyError as e:\n",
    "        print(f'WARNING Missing Expected Field {e} from entry {bib_id}: \\\"', b[\"title\"][:30],\"...\"*(len(b['title'])>30),\"\\\"\")\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'year': '2018', 'url': 'https://las.inf.ethz.ch/files/Mutny2018b.pdf', 'title': 'Efficient High Dimensional Bayesian Optimization with Additivity and Quadrature Fourier Features', 'month': 'December', 'booktitle': 'Neural and Information Processing Systems (NeurIPS)', 'author': \"Mutn{\\\\'y}, Mojmir and Krause, Andreas\", 'abstract': 'We develop an efficient and provably no-regret Bayesian optimization (BO) algorithm for optimization of black-box functions in high dimensions. We assume a generalized additive model with possibly overlapping variable groups. When the groups do not overlap, we are able to provide the first provably no-regret\\\\emph {polynomial time}(in the number of evaluations of the acquisition function) algorithm for solving high dimensional BO. To make the optimization efficient and feasible, we introduce a novel deterministic Fourier Features approximation based on numerical integration with detailed analysis for the squared exponential kernel. The error of this approximation decreases\\\\emph {exponentially} with the number of features, and allows for a precise approximation of both posterior mean and variance. In addition, the kernel matrix inversion improves in its complexity from cubic to essentially linear in the number of data points measured in basic arithmetic operations.', 'ENTRYTYPE': 'inproceedings', 'ID': 'Mutny2018b'}\n",
      "2018-12-01\n",
      "---\n",
      "title: \"Efficient High Dimensional Bayesian Optimization with Additivity and Quadrature Fourier Features\"\n",
      "\n",
      "permalink: /publication/2018-12-01-Efficient-High-Dimensional-Bayesian-Optimization-with-Additivity-and-Quadrature-Fourier-Features\n",
      "date: 2018-12-01\n",
      "venue: 'Neural and Information Processing Systems (NeurIPS)'\n",
      "url: 'https://las.inf.ethz.ch/files/Mutny2018b.pdf'\n",
      "---\n",
      "\n",
      "Mutny, Mojmir and Krause, Andreas, Efficient High Dimensional Bayesian Optimization with Additivity and Quadrature Fourier Features.\", 2018. Neural and Information Processing Systems (NeurIPS)\n",
      "\n",
      "**Abstract**: We develop an efficient and provably no-regret Bayesian optimization (BO) algorithm for optimization of black-box functions in high dimensions. We assume a generalized additive model with possibly overlapping variable groups. When the groups do not overlap, we are able to provide the first provably no-regret\\emph {polynomial time}(in the number of evaluations of the acquisition function) algorithm for solving high dimensional BO. To make the optimization efficient and feasible, we introduce a novel deterministic Fourier Features approximation based on numerical integration with detailed analysis for the squared exponential kernel. The error of this approximation decreases\\emph {exponentially} with the number of features, and allows for a precise approximation of both posterior mean and variance. In addition, the kernel matrix inversion improves in its complexity from cubic to essentially linear in the number of data points measured in basic arithmetic operations.\n",
      "\n",
      "[Full text here](https://las.inf.ethz.ch/files/Mutny2018b.pdf){:target=\"_blank\"}\n",
      "<!--more-->\n",
      "{'year': '2018', 'volume': '36', 'url': 'https://arxiv.org/pdf/1705.02005.pdf', 'title': 'Parallel Stochastic Newton Method', 'timestamp': '2017.07.25', 'pages': '405--426', 'owner': 'mojko', 'number': '3', 'journal': 'Journal of Computational Mathematics', 'file': ':Mutny2017.pdf:PDF', 'author': \"Mutn{\\\\'y}, Mojm{\\\\'\\\\i}r and Richt{\\\\'a}rik, Peter\", 'abstract': 'We propose a parallel stochastic Newton method (PSN) for minimizing unconstrained\\nsmooth convex functions. We analyze the method in the strongly convex case, and give conditions under which acceleration can be expected when compared to its serial counter-part. We show how PSN can be applied to the large quadratic function minimization in general, and empirical risk minimization problems. We demonstrate the practical efficiency of the method through numerical experiments and models of simple matrix classes.', 'ENTRYTYPE': 'article', 'ID': 'Mutny2018a'}\n",
      "2018-01-01\n",
      "---\n",
      "title: \"Parallel Stochastic Newton Method\"\n",
      "\n",
      "permalink: /publication/2018-01-01-Parallel-Stochastic-Newton-Method\n",
      "date: 2018-01-01\n",
      "venue: 'Journal of Computational Mathematics'\n",
      "url: 'https://arxiv.org/pdf/1705.02005.pdf'\n",
      "---\n",
      "\n",
      "Mutny, Mojmir and Richtarik, Peter, Parallel Stochastic Newton Method.\", 2018. Journal of Computational Mathematics\n",
      "\n",
      "**Abstract**: We propose a parallel stochastic Newton method (PSN) for minimizing unconstrained\n",
      "smooth convex functions. We analyze the method in the strongly convex case, and give conditions under which acceleration can be expected when compared to its serial counter-part. We show how PSN can be applied to the large quadratic function minimization in general, and empirical risk minimization problems. We demonstrate the practical efficiency of the method through numerical experiments and models of simple matrix classes.\n",
      "\n",
      "[Full text here](https://arxiv.org/pdf/1705.02005.pdf){:target=\"_blank\"}\n",
      "<!--more-->\n",
      "{'year': '2020', 'url': 'https://las.inf.ethz.ch/files/Mutny2020.pdf', 'title': 'Experimental Design for Optimization of Orthogonal Projection Pursuit Models', 'booktitle': 'Proceedings of the 34th AAAI Conference on Artificial Intelligence (AAAI)', 'bdsk-url-1': 'https://las.inf.ethz.ch/files/Mutny2020.pdf', 'author': \"Mutn{\\\\'y}, Mojm{\\\\'\\\\i}r and Kirschner, Johannes and Krause, Andreas\", 'abstract': 'Bayesian optimization and kernelized bandit algorithms are widely used techniques for sequential black box function optimization with applications in parameter tuning, control, robotics among many others. To be effective in high dimensional settings, previous approaches make additional assumptions, for example on low-dimensional subspaces or an additive structure. In this work, we go beyond the additivity assumption and use an orthogonal projection pursuit regression model, which strictly generalizes additive models. We present a two-stage algorithm motivated by experimental design to first decorrelate the additive components. Subsequently, the bandit optimization benefits from the statistically efficient additive model. Our method provably decorrelates the fully additive model and achieves optimal sublinear simple regret in terms of the number of function evaluations. To prove the rotation recovery, we derive novel concentration inequalities for linear regression on subspaces. In addition, we specifically address the issue of acquisition function optimization and present two domain dependent efficient algorithms. We validate the algorithm numerically on synthetic as well as real-world optimization problems.', 'ENTRYTYPE': 'inproceedings', 'ID': 'Mutny2020'}\n",
      "2020-01-01\n",
      "---\n",
      "title: \"Experimental Design for Optimization of Orthogonal Projection Pursuit Models\"\n",
      "\n",
      "permalink: /publication/2020-01-01-Experimental-Design-for-Optimization-of-Orthogonal-Projection-Pursuit-Models\n",
      "date: 2020-01-01\n",
      "venue: 'Proceedings of the 34th AAAI Conference on Artificial Intelligence (AAAI)'\n",
      "url: 'https://las.inf.ethz.ch/files/Mutny2020.pdf'\n",
      "---\n",
      "\n",
      "Mutny, Mojmir and Kirschner, Johannes and Krause, Andreas, Experimental Design for Optimization of Orthogonal Projection Pursuit Models.\", 2020. Proceedings of the 34th AAAI Conference on Artificial Intelligence (AAAI)\n",
      "\n",
      "**Abstract**: Bayesian optimization and kernelized bandit algorithms are widely used techniques for sequential black box function optimization with applications in parameter tuning, control, robotics among many others. To be effective in high dimensional settings, previous approaches make additional assumptions, for example on low-dimensional subspaces or an additive structure. In this work, we go beyond the additivity assumption and use an orthogonal projection pursuit regression model, which strictly generalizes additive models. We present a two-stage algorithm motivated by experimental design to first decorrelate the additive components. Subsequently, the bandit optimization benefits from the statistically efficient additive model. Our method provably decorrelates the fully additive model and achieves optimal sublinear simple regret in terms of the number of function evaluations. To prove the rotation recovery, we derive novel concentration inequalities for linear regression on subspaces. In addition, we specifically address the issue of acquisition function optimization and present two domain dependent efficient algorithms. We validate the algorithm numerically on synthetic as well as real-world optimization problems.\n",
      "\n",
      "[Full text here](https://las.inf.ethz.ch/files/Mutny2020.pdf){:target=\"_blank\"}\n",
      "<!--more-->\n",
      "{'year': '2020', 'url': 'https://arxiv.org/pdf/1910.11561.pdf', 'title': 'Convergence Analysis of Block Coordinate Algorithms with Determinantal Sampling', 'booktitle': 'Proceedings of the 23rd International Conference on Artificial Intelligence and Statistics (AISTATS)', 'bdsk-url-1': 'https://arxiv.org/pdf/1910.11561.pdf', 'author': \"Mutn{\\\\'y}, Mojm{\\\\'\\\\i}r and Derezisnki, Michal and Krause, Andreas\", 'abstract': 'We analyze the convergence rate of the randomized Newton-like method introduced by Qu et. al. (2016) for smooth and convex objectives, which uses random coordinate blocks of a Hessian-over-approximation matrix $\\\\mathbf{M}$ instead of the true Hessian. The convergence analysis of the algorithm is challenging because of its complex dependence on the structure of $\\\\mathbf{M}$. However, we show that when the coordinate blocks are sampled with probability proportional to their determinant, the convergence rate depends solely on the eigenvalue distribution of matrix $\\\\mathbf{M}$, and has an analytically tractable form. To do so, we derive a fundamental new expectation formula for determinantal point processes. We show that determinantal sampling allows us to reason about the optimal subset size of blocks in terms of the spectrum of $\\\\mathbf{M}$. Additionally, we provide a numerical evaluation of our analysis, demonstrating cases where determinantal sampling is superior or on par with uniform sampling.', 'ENTRYTYPE': 'inproceedings', 'ID': 'Mutny2020b'}\n",
      "2020-01-01\n",
      "---\n",
      "title: \"Convergence Analysis of Block Coordinate Algorithms with Determinantal Sampling\"\n",
      "\n",
      "permalink: /publication/2020-01-01-Convergence-Analysis-of-Block-Coordinate-Algorithms-with-Determinantal-Sampling\n",
      "date: 2020-01-01\n",
      "venue: 'Proceedings of the 23rd International Conference on Artificial Intelligence and Statistics (AISTATS)'\n",
      "url: 'https://arxiv.org/pdf/1910.11561.pdf'\n",
      "---\n",
      "\n",
      "Mutny, Mojmir and Derezisnki, Michal and Krause, Andreas, Convergence Analysis of Block Coordinate Algorithms with Determinantal Sampling.\", 2020. Proceedings of the 23rd International Conference on Artificial Intelligence and Statistics (AISTATS)\n",
      "\n",
      "**Abstract**: We analyze the convergence rate of the randomized Newton-like method introduced by Qu et. al. (2016) for smooth and convex objectives, which uses random coordinate blocks of a Hessian-over-approximation matrix $\\mathbf{M}$ instead of the true Hessian. The convergence analysis of the algorithm is challenging because of its complex dependence on the structure of $\\mathbf{M}$. However, we show that when the coordinate blocks are sampled with probability proportional to their determinant, the convergence rate depends solely on the eigenvalue distribution of matrix $\\mathbf{M}$, and has an analytically tractable form. To do so, we derive a fundamental new expectation formula for determinantal point processes. We show that determinantal sampling allows us to reason about the optimal subset size of blocks in terms of the spectrum of $\\mathbf{M}$. Additionally, we provide a numerical evaluation of our analysis, demonstrating cases where determinantal sampling is superior or on par with uniform sampling.\n",
      "\n",
      "[Full text here](https://arxiv.org/pdf/1910.11561.pdf){:target=\"_blank\"}\n",
      "<!--more-->\n",
      "{'year': '2019', 'url': 'https://las.inf.ethz.ch/files/kirschner19swissfel.pdf', 'title': 'Bayesian Optimization for Fast and Safe Parameter Tuning of SwissFEL', 'primaryclass': 'cs.LG', 'date-modified': '2019-10-22 11:58:27 +0000', 'booktitle': 'Proc. International Free-Electron Laser Conference (FEL2019)', 'bdsk-url-1': 'files/kirschner19swissfel.pdf', 'author': \"Kirschner, Johannes and Nonnenmacher, Manuel and Mutn{\\\\'y}, Mojm{\\\\'\\\\i}r and Hiller, Nicole and Adelmann, Andreas and Ischebeck, Rasmus and Krause, Andreas\", 'archiveprefix': 'arXiv', 'abstract': 'Parameter tuning is a notoriously time-consuming task in accelerator facilities. As tool for global optimization with noisy evaluations, Bayesian optimization was recently shown to outperform alternative methods. By learning a model of the underlying function using all available data, the next evaluation can be chosen carefully to find the optimum with as few steps as possible and without violating any safety constraints. However, the per-step computation time increases significantly with the number of parameters and the generality of the approach can lead to slow convergence on functions that are easier to optimize. To overcome these limitations, we divide the global problem into sequential subproblems that can be solved efficiently using safe Bayesian optimization. This allows us to trade off local and global convergence and to adapt to additional structure in the objective function. Further, we provide slice-plots of the function as user feedback during the optimization. We showcase how we use our algorithm to tune up the FEL output of SwissFEL with up to 40 parameters simultaneously, and reach convergence within reasonable tuning times in the order of 30 minutes (< 2000 steps).', 'ENTRYTYPE': 'inproceedings', 'ID': 'Kirschner2019b'}\n",
      "2019-01-01\n",
      "---\n",
      "title: \"Bayesian Optimization for Fast and Safe Parameter Tuning of SwissFEL\"\n",
      "\n",
      "permalink: /publication/2019-01-01-Bayesian-Optimization-for-Fast-and-Safe-Parameter-Tuning-of-SwissFEL\n",
      "date: 2019-01-01\n",
      "venue: 'Proc. International Free-Electron Laser Conference (FEL2019)'\n",
      "url: 'https://las.inf.ethz.ch/files/kirschner19swissfel.pdf'\n",
      "---\n",
      "\n",
      "Kirschner, Johannes and Nonnenmacher, Manuel and Mutny, Mojmir and Hiller, Nicole and Adelmann, Andreas and Ischebeck, Rasmus and Krause, Andreas, Bayesian Optimization for Fast and Safe Parameter Tuning of SwissFEL.\", 2019. Proc. International Free-Electron Laser Conference (FEL2019)\n",
      "\n",
      "**Abstract**: Parameter tuning is a notoriously time-consuming task in accelerator facilities. As tool for global optimization with noisy evaluations, Bayesian optimization was recently shown to outperform alternative methods. By learning a model of the underlying function using all available data, the next evaluation can be chosen carefully to find the optimum with as few steps as possible and without violating any safety constraints. However, the per-step computation time increases significantly with the number of parameters and the generality of the approach can lead to slow convergence on functions that are easier to optimize. To overcome these limitations, we divide the global problem into sequential subproblems that can be solved efficiently using safe Bayesian optimization. This allows us to trade off local and global convergence and to adapt to additional structure in the objective function. Further, we provide slice-plots of the function as user feedback during the optimization. We showcase how we use our algorithm to tune up the FEL output of SwissFEL with up to 40 parameters simultaneously, and reach convergence within reasonable tuning times in the order of 30 minutes (< 2000 steps).\n",
      "\n",
      "[Full text here](https://las.inf.ethz.ch/files/kirschner19swissfel.pdf){:target=\"_blank\"}\n",
      "<!--more-->\n",
      "{'year': '2020', 'volume': '7', 'url': 'https://www.liebertpub.com/doi/abs/10.1089/soro.2018.0162', 'title': 'MakeSense: Automated Sensor Design for Proprioceptive Soft Robots', 'publisher': 'Mary Ann Liebert, Inc., publishers 140 Huguenot Street, 3rd Floor New~{\\\\ldots}', 'pages': '332--345', 'number': '3', 'journal': 'Soft Robotics', 'author': 'Tapia, Javier and Knoop, Espen and Mutn{\\\\\\'y}, Mojm{\\\\\\'\\\\i}r and Otaduy, Miguel A and B{\\\\\"a}cher, Moritz', 'abstract': 'Soft robots have applications in safe human--robot interactions, manipulation of fragile objects, and locomotion in challenging and unstructured environments. In this article, we present a computational method for augmenting soft robots with proprioceptive sensing capabilities. Our method automatically computes a minimal stretch-receptive sensor network to user-provided soft robotic designs, which is optimized to perform well under a set of user-specified deformation-force pairs. The sensorized robots are able to reconstruct their full deformation state, under interaction forces. We cast our sensor design as a subselection problem, selecting a minimal set of sensors from a large set of fabricable ones, which minimizes the error when sensing specified deformation-force pairs. Unique to our approach is the use of an analytical gradient of our reconstruction performance measure with respect to selection variables. We demonstrate our technique on a bending bar and gripper example, illustrating more complex designs with a simulated tentacle.', 'ENTRYTYPE': 'article', 'ID': 'Tapia2020'}\n",
      "2020-01-01\n",
      "---\n",
      "title: \"MakeSense: Automated Sensor Design for Proprioceptive Soft Robots\"\n",
      "\n",
      "permalink: /publication/2020-01-01-MakeSense-Automated-Sensor-Design-for-Proprioceptive-Soft-Robots\n",
      "date: 2020-01-01\n",
      "venue: 'Soft Robotics'\n",
      "url: 'https://www.liebertpub.com/doi/abs/10.1089/soro.2018.0162'\n",
      "---\n",
      "\n",
      "Tapia, Javier and Knoop, Espen and Mutny, Mojmir and Otaduy, Miguel A and Bacher, Moritz, MakeSense: Automated Sensor Design for Proprioceptive Soft Robots.\", 2020. Soft Robotics\n",
      "\n",
      "**Abstract**: Soft robots have applications in safe human--robot interactions, manipulation of fragile objects, and locomotion in challenging and unstructured environments. In this article, we present a computational method for augmenting soft robots with proprioceptive sensing capabilities. Our method automatically computes a minimal stretch-receptive sensor network to user-provided soft robotic designs, which is optimized to perform well under a set of user-specified deformation-force pairs. The sensorized robots are able to reconstruct their full deformation state, under interaction forces. We cast our sensor design as a subselection problem, selecting a minimal set of sensors from a large set of fabricable ones, which minimizes the error when sensing specified deformation-force pairs. Unique to our approach is the use of an analytical gradient of our reconstruction performance measure with respect to selection variables. We demonstrate our technique on a bending bar and gripper example, illustrating more complex designs with a simulated tentacle.\n",
      "\n",
      "[Full text here](https://www.liebertpub.com/doi/abs/10.1089/soro.2018.0162){:target=\"_blank\"}\n",
      "<!--more-->\n",
      "{'year': '2020', 'url': 'https://arxiv.org/abs/2006.03875', 'title': 'Coresets via Bilevel Optimization for Continual Learning and Streaming', 'journal': 'Neural and Information Processing Systems (NeurIPS) 2020', 'booktitle': 'Proc. Neural Information Processing Systems (NeurIPS)', 'author': \"Borsos, Zal{\\\\'a}n and Mutn{\\\\'y}, Mojm{\\\\'\\\\i}r and Krause, Andreas\", 'abstract': 'Coresets are small data summaries that are sufficient for model training. They can be maintained online, enabling efficient handling of large data streams under resource constraints. However, existing constructions are limited to simple models such as k-means and logistic regression. In this work, we propose a novel coreset construction via cardinality-constrained bilevel optimization. We show how our framework can efficiently generate coresets for deep neural networks, and demonstrate its empirical benefits in continual learning and in streaming settings.', 'ENTRYTYPE': 'inproceedings', 'ID': 'Borsos2020'}\n",
      "2020-01-01\n",
      "---\n",
      "title: \"Coresets via Bilevel Optimization for Continual Learning and Streaming\"\n",
      "\n",
      "permalink: /publication/2020-01-01-Coresets-via-Bilevel-Optimization-for-Continual-Learning-and-Streaming\n",
      "date: 2020-01-01\n",
      "venue: 'Proc. Neural Information Processing Systems (NeurIPS)'\n",
      "url: 'https://arxiv.org/abs/2006.03875'\n",
      "---\n",
      "\n",
      "Borsos, Zalan and Mutny, Mojmir and Krause, Andreas, Coresets via Bilevel Optimization for Continual Learning and Streaming.\", 2020. Proc. Neural Information Processing Systems (NeurIPS)\n",
      "\n",
      "**Abstract**: Coresets are small data summaries that are sufficient for model training. They can be maintained online, enabling efficient handling of large data streams under resource constraints. However, existing constructions are limited to simple models such as k-means and logistic regression. In this work, we propose a novel coreset construction via cardinality-constrained bilevel optimization. We show how our framework can efficiently generate coresets for deep neural networks, and demonstrate its empirical benefits in continual learning and in streaming settings.\n",
      "\n",
      "[Full text here](https://arxiv.org/abs/2006.03875){:target=\"_blank\"}\n",
      "<!--more-->\n",
      "{'year': '2021', 'url': 'https://arxiv.org/abs/2006.11022', 'title': 'Learning Controllers for Unstable Linear Quadratic Regulators from a Single Trajectory', 'journal': 'Learning for Dynamics \\\\& Controll (L4DC) 2021', 'booktitle': 'In proceedings of Learning for Dynamics \\\\& Control Conference', 'author': \"Treven, Lenart and Curi, Sebastian and Mutn{\\\\'y}, Mojm{\\\\'\\\\i}r and Krause, Andreas\", 'abstract': 'We present the first approach for learning--from a single trajectory--a linear quadratic regulator (LQR), even for unstable systems, without knowledge of the system dynamics and without requiring an initial stabilizing controller. Our central contribution is an efficient algorithm--\\\\emph {eXploration}--that quickly identifies a stabilizing controller. Our approach utilizes robust System Level Synthesis (SLS), and we prove that it succeeds in a constant number of iterations. Our approach can be used to initialize existing algorithms that require a stabilizing controller as input. When used in this way, it yields a method for learning LQRs from a single trajectory and even for unstable systems, while suffering at most regret.', 'ENTRYTYPE': 'inproceedings', 'ID': 'Treven2021'}\n",
      "2021-01-01\n",
      "---\n",
      "title: \"Learning Controllers for Unstable Linear Quadratic Regulators from a Single Trajectory\"\n",
      "\n",
      "permalink: /publication/2021-01-01-Learning-Controllers-for-Unstable-Linear-Quadratic-Regulators-from-a-Single-Trajectory\n",
      "date: 2021-01-01\n",
      "venue: 'In proceedings of Learning for Dynamics \\&amp; Control Conference'\n",
      "url: 'https://arxiv.org/abs/2006.11022'\n",
      "---\n",
      "\n",
      "Treven, Lenart and Curi, Sebastian and Mutny, Mojmir and Krause, Andreas, Learning Controllers for Unstable Linear Quadratic Regulators from a Single Trajectory.\", 2021. In proceedings of Learning for Dynamics \\& Control Conference\n",
      "\n",
      "**Abstract**: We present the first approach for learning--from a single trajectory--a linear quadratic regulator (LQR), even for unstable systems, without knowledge of the system dynamics and without requiring an initial stabilizing controller. Our central contribution is an efficient algorithm--\\emph {eXploration}--that quickly identifies a stabilizing controller. Our approach utilizes robust System Level Synthesis (SLS), and we prove that it succeeds in a constant number of iterations. Our approach can be used to initialize existing algorithms that require a stabilizing controller as input. When used in this way, it yields a method for learning LQRs from a single trajectory and even for unstable systems, while suffering at most regret.\n",
      "\n",
      "[Full text here](https://arxiv.org/abs/2006.11022){:target=\"_blank\"}\n",
      "<!--more-->\n",
      "{'year': '2021', 'url': 'http://proceedings.mlr.press/v139/mutny21a/mutny21a.pdf', 'title': 'No-regret Algorithms for Capturing Events in Poisson Point Processes', 'booktitle': 'Proc. International Conference for Machine Learning (ICML)', 'author': \"Mutn{\\\\'y}, Mojm{\\\\'\\\\i}r and Krause, Andreas\", 'abstract': 'Inhomogeneous Poisson point processes are widely used  models of event occurrences. We address \\\\emph{adaptive sensing of Poisson Point processes}, namely, maximizing the number of captured events subject to sensing costs. We encode prior assumptions on the rate function by modeling it as a member of a known \\\\emph{reproducing kernel Hilbert space} (RKHS). By partitioning the domain into separate small regions, and using heteroscedastic linear regression, we propose a tractable estimator of Poisson process rates for two feedback models: \\\\emph{count-record}, where exact locations of events are observed, and \\\\emph{histogram} feedback, where only counts of events are observed. We derive provably accurate anytime confidence estimates for our estimators for sequentially acquired Poisson count data. Using these, we formulate algorithms based on optimism that provably incur sublinear count-regret. We demonstrate the practicality of the method on problems from crime modeling, revenue maximization as well as environmental monitoring.', 'ENTRYTYPE': 'inproceedings', 'ID': 'Mutny2021a'}\n",
      "2021-01-01\n",
      "---\n",
      "title: \"No-regret Algorithms for Capturing Events in Poisson Point Processes\"\n",
      "\n",
      "permalink: /publication/2021-01-01-No-regret-Algorithms-for-Capturing-Events-in-Poisson-Point-Processes\n",
      "date: 2021-01-01\n",
      "venue: 'Proc. International Conference for Machine Learning (ICML)'\n",
      "url: 'http://proceedings.mlr.press/v139/mutny21a/mutny21a.pdf'\n",
      "---\n",
      "\n",
      "Mutny, Mojmir and Krause, Andreas, No-regret Algorithms for Capturing Events in Poisson Point Processes.\", 2021. Proc. International Conference for Machine Learning (ICML)\n",
      "\n",
      "**Abstract**: Inhomogeneous Poisson point processes are widely used  models of event occurrences. We address \\emph{adaptive sensing of Poisson Point processes}, namely, maximizing the number of captured events subject to sensing costs. We encode prior assumptions on the rate function by modeling it as a member of a known \\emph{reproducing kernel Hilbert space} (RKHS). By partitioning the domain into separate small regions, and using heteroscedastic linear regression, we propose a tractable estimator of Poisson process rates for two feedback models: \\emph{count-record}, where exact locations of events are observed, and \\emph{histogram} feedback, where only counts of events are observed. We derive provably accurate anytime confidence estimates for our estimators for sequentially acquired Poisson count data. Using these, we formulate algorithms based on optimism that provably incur sublinear count-regret. We demonstrate the practicality of the method on problems from crime modeling, revenue maximization as well as environmental monitoring.\n",
      "\n",
      "[Full text here](http://proceedings.mlr.press/v139/mutny21a/mutny21a.pdf){:target=\"_blank\"}\n",
      "<!--more-->\n",
      "{'year': '2019', 'title': 'Adaptive and Safe Bayesian Optimization in High Dimensions via One-Dimensional Subspaces', 'primaryclass': 'cs.LG', 'eprint': '1902.03229', 'booktitle': 'Proc. International Conference for Machine Learning (ICML)', 'author': \"Kirschner, Johannes and Mutn{\\\\'y}, Mojm{\\\\'\\\\i}r and Hiller, Nicole and Ischebeck, Rasmus and Krause, Andreas\", 'archiveprefix': 'arXiv', 'abstract': 'Bayesian optimization is known to be difficult to scale to high dimensions, because the acquisition step requires solving a non-convex optimization problem in the same search space. In order to scale the method and keep its benefits, we propose an algorithm (LineBO) that restricts the problem to a sequence of iteratively chosen one-dimensional sub-problems that can be solved efficiently. We show that our algorithm converges globally and obtains a fast local rate when the function is strongly convex. Further, if the objective has an invariant subspace, our method automatically adapts to the effective dimension without changing the algorithm. When combined with the SafeOpt algorithm to solve the sub-problems, we obtain the first safe Bayesian optimization algorithm with theoretical guarantees applicable in high-dimensional settings. We evaluate our method on multiple synthetic benchmarks, where we obtain competitive performance. Further, we deploy our algorithm to optimize the beam intensity of the Swiss Free Electron Laser with up to 40 parameters while satisfying safe operation constraints.', 'ENTRYTYPE': 'inproceedings', 'ID': 'Kirschner2019'}\n",
      "2019-01-01\n",
      "---\n",
      "title: \"Adaptive and Safe Bayesian Optimization in High Dimensions via One-Dimensional Subspaces\"\n",
      "\n",
      "permalink: /publication/2019-01-01-Adaptive-and-Safe-Bayesian-Optimization-in-High-Dimensions-via-One-Dimensional-Subspaces\n",
      "date: 2019-01-01\n",
      "venue: 'Proc. International Conference for Machine Learning (ICML)'\n",
      "---\n",
      "\n",
      "Kirschner, Johannes and Mutny, Mojmir and Hiller, Nicole and Ischebeck, Rasmus and Krause, Andreas, Adaptive and Safe Bayesian Optimization in High Dimensions via One-Dimensional Subspaces.\", 2019. Proc. International Conference for Machine Learning (ICML)\n",
      "\n",
      "**Abstract**: Bayesian optimization is known to be difficult to scale to high dimensions, because the acquisition step requires solving a non-convex optimization problem in the same search space. In order to scale the method and keep its benefits, we propose an algorithm (LineBO) that restricts the problem to a sequence of iteratively chosen one-dimensional sub-problems that can be solved efficiently. We show that our algorithm converges globally and obtains a fast local rate when the function is strongly convex. Further, if the objective has an invariant subspace, our method automatically adapts to the effective dimension without changing the algorithm. When combined with the SafeOpt algorithm to solve the sub-problems, we obtain the first safe Bayesian optimization algorithm with theoretical guarantees applicable in high-dimensional settings. We evaluate our method on multiple synthetic benchmarks, where we obtain competitive performance. Further, we deploy our algorithm to optimize the beam intensity of the Swiss Free Electron Laser with up to 40 parameters while satisfying safe operation constraints.\n",
      "\n",
      "Use [Google Scholar](https://scholar.google.com/scholar?q=Adaptive+and+Safe+Bayesian+Optimization+in+High+Dimensions+via+One+Dimensional+Subspaces){:target=\"_blank\"} for full citation<!--more-->\n",
      "{'year': '2022', 'url': 'https://arxiv.org/abs/2110.11181', 'title': 'Sensing Cox Processes via Posterior Sampling and Positive Bases', 'booktitle': 'Proceedings of the 25th International Conference on Artificial Intelligence and Statistics (AISTATS)', 'author': \"Mutn{\\\\'y}, Mojm{\\\\'\\\\i}r and Krause, Andreas\", 'abstract': 'We study adaptive sensing of Cox point processes, a widely used model from spatial statistics. We introduce three tasks: maximization of captured events, search for the maximum of the intensity function and learning level sets of the intensity function. We model the intensity function as a sample from a truncated Gaussian process, represented in a specially constructed positive basis. In this basis, the positivity constraint on the intensity function has a simple form. We show how the \\\\emph{minimal description positive basis} can be adapted to the covariance kernel, to non-stationarity and make connections to common positive bases from prior works. Our adaptive sensing algorithms use Langevin dynamics and are based on posterior sampling (\\\\textsc{Cox-Thompson}) and top-two posterior sampling (\\\\textsc{Top2}) principles. With latter, the difference between samples serves as a surrogate to the uncertainty. We demonstrate the approach using examples from environmental monitoring and crime rate modeling, and compare it to the classical Bayesian experimental design approach.', 'ENTRYTYPE': 'inproceedings', 'ID': 'Mutny2022'}\n",
      "2022-01-01\n",
      "---\n",
      "title: \"Sensing Cox Processes via Posterior Sampling and Positive Bases\"\n",
      "\n",
      "permalink: /publication/2022-01-01-Sensing-Cox-Processes-via-Posterior-Sampling-and-Positive-Bases\n",
      "date: 2022-01-01\n",
      "venue: 'Proceedings of the 25th International Conference on Artificial Intelligence and Statistics (AISTATS)'\n",
      "url: 'https://arxiv.org/abs/2110.11181'\n",
      "---\n",
      "\n",
      "Mutny, Mojmir and Krause, Andreas, Sensing Cox Processes via Posterior Sampling and Positive Bases.\", 2022. Proceedings of the 25th International Conference on Artificial Intelligence and Statistics (AISTATS)\n",
      "\n",
      "**Abstract**: We study adaptive sensing of Cox point processes, a widely used model from spatial statistics. We introduce three tasks: maximization of captured events, search for the maximum of the intensity function and learning level sets of the intensity function. We model the intensity function as a sample from a truncated Gaussian process, represented in a specially constructed positive basis. In this basis, the positivity constraint on the intensity function has a simple form. We show how the \\emph{minimal description positive basis} can be adapted to the covariance kernel, to non-stationarity and make connections to common positive bases from prior works. Our adaptive sensing algorithms use Langevin dynamics and are based on posterior sampling (\\textsc{Cox-Thompson}) and top-two posterior sampling (\\textsc{Top2}) principles. With latter, the difference between samples serves as a surrogate to the uncertainty. We demonstrate the approach using examples from environmental monitoring and crime rate modeling, and compare it to the classical Bayesian experimental design approach.\n",
      "\n",
      "[Full text here](https://arxiv.org/abs/2110.11181){:target=\"_blank\"}\n",
      "<!--more-->\n",
      "{'year': '2022', 'url': 'https://proceedings.mlr.press/v151/nava22a/nava22a.pdf', 'title': 'Diversified Sampling for Batched Bayesian Optimization with Determinantal Point Processes', 'eprint': '2110.11665', 'booktitle': 'Proceedings of the 25th International Conference on Artificial Intelligence and Statistics (AISTATS)', 'author': \"Nava, Elvis and Mutn{\\\\'y}, Mojm{\\\\'\\\\i}r and Krause, Andreas\", 'abstract': 'In this work we introduced DPP-BBO, a natural and easily applicable framework for enhancing batch diversity in BBO algorithms which works in more settings than previous diversification strategies: it is directly applicable to the continuous domain case, when due to approximation and non-standard models we are unable to compute hallucinations or confidence intervals (as in the Cox process example), or more generally when used in combination with any randomized BBO sampling scheme or arbitrary diversity kernel. Moreover, for DPP-TS we show improved theoretical guarantees and strong practical performance on simple regret.', 'ENTRYTYPE': 'inproceedings', 'ID': 'Nava2022'}\n",
      "2022-01-01\n",
      "---\n",
      "title: \"Diversified Sampling for Batched Bayesian Optimization with Determinantal Point Processes\"\n",
      "\n",
      "permalink: /publication/2022-01-01-Diversified-Sampling-for-Batched-Bayesian-Optimization-with-Determinantal-Point-Processes\n",
      "date: 2022-01-01\n",
      "venue: 'Proceedings of the 25th International Conference on Artificial Intelligence and Statistics (AISTATS)'\n",
      "url: 'https://proceedings.mlr.press/v151/nava22a/nava22a.pdf'\n",
      "---\n",
      "\n",
      "Nava, Elvis and Mutny, Mojmir and Krause, Andreas, Diversified Sampling for Batched Bayesian Optimization with Determinantal Point Processes.\", 2022. Proceedings of the 25th International Conference on Artificial Intelligence and Statistics (AISTATS)\n",
      "\n",
      "**Abstract**: In this work we introduced DPP-BBO, a natural and easily applicable framework for enhancing batch diversity in BBO algorithms which works in more settings than previous diversification strategies: it is directly applicable to the continuous domain case, when due to approximation and non-standard models we are unable to compute hallucinations or confidence intervals (as in the Cox process example), or more generally when used in combination with any randomized BBO sampling scheme or arbitrary diversity kernel. Moreover, for DPP-TS we show improved theoretical guarantees and strong practical performance on simple regret.\n",
      "\n",
      "[Full text here](https://proceedings.mlr.press/v151/nava22a/nava22a.pdf){:target=\"_blank\"}\n",
      "<!--more-->\n",
      "{'year': '2022', 'url': 'https://arxiv.org/abs/2205.13627', 'title': 'Experimental Design of Linear Functionals in Reproducing Kernel Hilbert Spaces', 'month': 'November', 'booktitle': 'Proc. Neural Information Processing Systems (NeurIPS)', 'author': \"Mutn{\\\\'y}, Mojm{\\\\'\\\\i}r and Krause, Andreas\", 'abstract': 'Optimal experimental design seeks to determine the most informative allocation of experiments  to infer an unknown statistical quantity. In this work, we investigate optimal design of experiments for {\\\\em estimation of linear functionals in reproducing kernel Hilbert spaces (RKHSs)}. This problem has been extensively studied in the linear regression setting\\nunder an estimability condition, which allows estimating parameters without bias. We generalize this framework to RKHSs, and allow for the linear functional to be only approximately inferred, i.e., with a fixed bias. This scenario captures many important modern applications such as estimation of gradient maps, integrals and solutions to differential equations. We provide algorithms for constructing bias-aware designs for linear functionals. We derive non-asymptotic confidence sets for fixed and adaptive designs under sub-Gaussian noise, enabling us to certify estimation with bounded error with high probability.', 'ENTRYTYPE': 'inproceedings', 'ID': 'Mutny2022b'}\n",
      "2022-11-01\n",
      "---\n",
      "title: \"Experimental Design of Linear Functionals in Reproducing Kernel Hilbert Spaces\"\n",
      "\n",
      "permalink: /publication/2022-11-01-Experimental-Design-of-Linear-Functionals-in-Reproducing-Kernel-Hilbert-Spaces\n",
      "date: 2022-11-01\n",
      "venue: 'Proc. Neural Information Processing Systems (NeurIPS)'\n",
      "url: 'https://arxiv.org/abs/2205.13627'\n",
      "---\n",
      "\n",
      "Mutny, Mojmir and Krause, Andreas, Experimental Design of Linear Functionals in Reproducing Kernel Hilbert Spaces.\", 2022. Proc. Neural Information Processing Systems (NeurIPS)\n",
      "\n",
      "**Abstract**: Optimal experimental design seeks to determine the most informative allocation of experiments  to infer an unknown statistical quantity. In this work, we investigate optimal design of experiments for {\\em estimation of linear functionals in reproducing kernel Hilbert spaces (RKHSs)}. This problem has been extensively studied in the linear regression setting\n",
      "under an estimability condition, which allows estimating parameters without bias. We generalize this framework to RKHSs, and allow for the linear functional to be only approximately inferred, i.e., with a fixed bias. This scenario captures many important modern applications such as estimation of gradient maps, integrals and solutions to differential equations. We provide algorithms for constructing bias-aware designs for linear functionals. We derive non-asymptotic confidence sets for fixed and adaptive designs under sub-Gaussian noise, enabling us to certify estimation with bounded error with high probability.\n",
      "\n",
      "[Full text here](https://arxiv.org/abs/2205.13627){:target=\"_blank\"}\n",
      "<!--more-->\n",
      "{'year': '2021', 'url': 'https://proceedings.mlr.press/v132/jourdan21a.html', 'title': 'Efficient Pure Exploration for Combinatorial Bandits with Semi-Bandit Feedback', 'pdf': 'http://proceedings.mlr.press/v132/jourdan21a/jourdan21a.pdf', 'booktitle': 'Proceedings of the 32nd International Conference on Algorithmic Learning Theory (ALT)', 'author': \"Jourdan, Marc and Mutn{\\\\'y}, Mojm{\\\\'\\\\i}r and Kirschner, Johannes and Krause, Andreas\", 'abstract': 'Combinatorial bandits with semi-bandit feedback generalize multi-armed bandits, where the agent chooses sets of arms and observes a noisy reward for each arm contained in the chosen set. The action set satisfies a given structure such as forming a base of a matroid or a path in a graph. We focus on the pure-exploration problem of identifying the best arm with fixed confidence, as well as a more general setting, where the structure of the answer set differs from the one of the action set. Using the recently popularized game framework, we interpret this problem as a sequential zero-sum game and develop a CombGame meta-algorithm whose instances are asymptotically optimal algorithms with finite time guarantees. In addition to comparing two families of learners to instantiate our meta-algorithm, the main contribution of our work is a specific oracle efficient instance for best-arm identification with combinatorial actions. Based on a projection-free online learning algorithm for convex polytopes, it is the first computationally efficient algorithm which is asymptotically optimal and has competitive empirical performance.', 'ENTRYTYPE': 'inproceedings', 'ID': 'Jourdan2021'}\n",
      "2021-01-01\n",
      "---\n",
      "title: \"Efficient Pure Exploration for Combinatorial Bandits with Semi-Bandit Feedback\"\n",
      "\n",
      "permalink: /publication/2021-01-01-Efficient-Pure-Exploration-for-Combinatorial-Bandits-with-Semi-Bandit-Feedback\n",
      "date: 2021-01-01\n",
      "venue: 'Proceedings of the 32nd International Conference on Algorithmic Learning Theory (ALT)'\n",
      "url: 'https://proceedings.mlr.press/v132/jourdan21a.html'\n",
      "---\n",
      "\n",
      "Jourdan, Marc and Mutny, Mojmir and Kirschner, Johannes and Krause, Andreas, Efficient Pure Exploration for Combinatorial Bandits with Semi-Bandit Feedback.\", 2021. Proceedings of the 32nd International Conference on Algorithmic Learning Theory (ALT)\n",
      "\n",
      "**Abstract**: Combinatorial bandits with semi-bandit feedback generalize multi-armed bandits, where the agent chooses sets of arms and observes a noisy reward for each arm contained in the chosen set. The action set satisfies a given structure such as forming a base of a matroid or a path in a graph. We focus on the pure-exploration problem of identifying the best arm with fixed confidence, as well as a more general setting, where the structure of the answer set differs from the one of the action set. Using the recently popularized game framework, we interpret this problem as a sequential zero-sum game and develop a CombGame meta-algorithm whose instances are asymptotically optimal algorithms with finite time guarantees. In addition to comparing two families of learners to instantiate our meta-algorithm, the main contribution of our work is a specific oracle efficient instance for best-arm identification with combinatorial actions. Based on a projection-free online learning algorithm for convex polytopes, it is the first computationally efficient algorithm which is asymptotically optimal and has competitive empirical performance.\n",
      "\n",
      "[Full text here](https://proceedings.mlr.press/v132/jourdan21a.html){:target=\"_blank\"}\n",
      "<!--more-->\n",
      "{'year': '2024', 'title': 'Data Summarization via Bilevel Optimization', 'primaryclass': 'cs.LG', 'journal': 'JMLR', 'eprint': '2109.12534', 'author': \"Borsos, Zal{\\\\'a}n and Mutn{\\\\'y}, Mojm{\\\\'\\\\i}r and Tagliasacchi, Marco and Krause, Andreas\", 'archiveprefix': 'arXiv', 'abstract': 'The increasing availability of massive data sets poses a series of challenges for machine learning. Prominent among these is the need to learn models under hardware or human resource constraints. In such resource-constrained settings, a simple yet powerful approach is to operate on small subsets of the data. Coresets are weighted subsets of the data that provide approximation guarantees for the optimization objective. However, existing coreset constructions are highly model-specific and are limited to simple models such as linear regression, logistic regression, and k-means. In this work, we propose a generic coreset construction framework that formulates the coreset selection as a cardinality-constrained bilevel optimization problem. In contrast to existing approaches, our framework does not require model-specific adaptations and applies to any twice differentiable model, including neural networks. We show the effectiveness of our framework for a wide range of models in various settings, including training non-convex models online and batch active learning.', 'ENTRYTYPE': 'article', 'ID': 'Borsos2021'}\n",
      "2024-01-01\n",
      "---\n",
      "title: \"Data Summarization via Bilevel Optimization\"\n",
      "\n",
      "permalink: /publication/2024-01-01-Data-Summarization-via-Bilevel-Optimization\n",
      "date: 2024-01-01\n",
      "venue: 'JMLR'\n",
      "---\n",
      "\n",
      "Borsos, Zalan and Mutny, Mojmir and Tagliasacchi, Marco and Krause, Andreas, Data Summarization via Bilevel Optimization.\", 2024. JMLR\n",
      "\n",
      "**Abstract**: The increasing availability of massive data sets poses a series of challenges for machine learning. Prominent among these is the need to learn models under hardware or human resource constraints. In such resource-constrained settings, a simple yet powerful approach is to operate on small subsets of the data. Coresets are weighted subsets of the data that provide approximation guarantees for the optimization objective. However, existing coreset constructions are highly model-specific and are limited to simple models such as linear regression, logistic regression, and k-means. In this work, we propose a generic coreset construction framework that formulates the coreset selection as a cardinality-constrained bilevel optimization problem. In contrast to existing approaches, our framework does not require model-specific adaptations and applies to any twice differentiable model, including neural networks. We show the effectiveness of our framework for a wide range of models in various settings, including training non-convex models online and batch active learning.\n",
      "\n",
      "Use [Google Scholar](https://scholar.google.com/scholar?q=Data+Summarization+via+Bilevel+Optimization){:target=\"_blank\"} for full citation<!--more-->\n",
      "{'year': '2023', 'url': 'https://arxiv.org/abs/2206.14332', 'title': 'Active Exploration via Experiment Design in Markov Chains', 'keywords': 'Machine Learning (cs.LG), Methodology (stat.ME), Machine Learning (stat.ML), FOS: Computer and information sciences', 'howpublished': 'AISTATS 2023', 'doi': '10.48550/ARXIV.2206.14332', 'copyright': 'arXiv.org perpetual, non-exclusive license', 'booktitle': 'Proceedings of the 26th International Conference on Artificial Intelligence and Statistics (AISTATS)', 'author': \"Mutn{\\\\'y}, Mojm{\\\\'\\\\i}r and Janik, Tadeusz and Krause, Andreas\", 'abstract': 'A key challenge in science and engineering is to design experiments to learn about some unknown quantity of interest. Classical experimental design optimally allocates the experimental budget to maximize a notion of utility (e.g., reduction in uncertainty about the unknown quantity). We consider a rich setting, where the experiments are associated with states in a {\\\\em Markov chain}, and we can only choose them by selecting a {\\\\em policy} controlling the state transitions. This problem captures important applications, from exploration in reinforcement learning to spatial monitoring tasks. We propose an algorithm -- \\\\textsc{markov-design} -- that efficiently selects policies whose measurement allocation \\\\emph{provably converges to the optimal one}. The algorithm is sequential in nature, adapting its choice of policies (experiments) informed by past measurements. In addition to our theoretical analysis, we showcase our framework on applications in ecological surveillance and pharmacology.', 'ENTRYTYPE': 'inproceedings', 'ID': 'Mutny2023'}\n",
      "2023-01-01\n",
      "---\n",
      "title: \"Active Exploration via Experiment Design in Markov Chains\"\n",
      "\n",
      "permalink: /publication/2023-01-01-Active-Exploration-via-Experiment-Design-in-Markov-Chains\n",
      "date: 2023-01-01\n",
      "venue: 'Proceedings of the 26th International Conference on Artificial Intelligence and Statistics (AISTATS)'\n",
      "url: 'https://arxiv.org/abs/2206.14332'\n",
      "---\n",
      "\n",
      "Mutny, Mojmir and Janik, Tadeusz and Krause, Andreas, Active Exploration via Experiment Design in Markov Chains.\", 2023. Proceedings of the 26th International Conference on Artificial Intelligence and Statistics (AISTATS)\n",
      "\n",
      "**Abstract**: A key challenge in science and engineering is to design experiments to learn about some unknown quantity of interest. Classical experimental design optimally allocates the experimental budget to maximize a notion of utility (e.g., reduction in uncertainty about the unknown quantity). We consider a rich setting, where the experiments are associated with states in a {\\em Markov chain}, and we can only choose them by selecting a {\\em policy} controlling the state transitions. This problem captures important applications, from exploration in reinforcement learning to spatial monitoring tasks. We propose an algorithm -- \\textsc{markov-design} -- that efficiently selects policies whose measurement allocation \\emph{provably converges to the optimal one}. The algorithm is sequential in nature, adapting its choice of policies (experiments) informed by past measurements. In addition to our theoretical analysis, we showcase our framework on applications in ecological surveillance and pharmacology.\n",
      "\n",
      "[Full text here](https://arxiv.org/abs/2206.14332){:target=\"_blank\"}\n",
      "<!--more-->\n",
      "{'year': '2022', 'volume': '25', 'url': 'https://link.aps.org/doi/10.1103/PhysRevAccelBeams.25.062802', 'title': 'Tuning particle accelerators with safety constraints using Bayesian optimization', 'publisher': 'American Physical Society', 'pages': '062802', 'numpages': '14', 'month': 'Jun', 'journal': 'Phys. Rev. Accel. Beams', 'issue': '6', 'doi': '10.1103/PhysRevAccelBeams.25.062802', 'author': \"Kirschner, Johannes and Mutn{\\\\'y}, Mojm{\\\\'\\\\i}r and Krause, Andreas and {Coello de Portugal}, Jaime and Hiller, Nicole and Snuverink, Jochem\", 'abstract': 'Tuning machine parameters of particle accelerators is a repetitive and time-consuming task that is challenging to automate. While many off-the-shelf optimization algorithms are available, in practice their use is limited because most methods do not account for safety-critical constraints in each iteration, such as loss signals or step-size limitations. One notable exception is safe Bayesian optimization, which is a data-driven tuning approach for global optimization with noisy feedback. We propose and evaluate a step-size limited variant of safe Bayesian optimization on two research facilities of the PSI:(a) the SwissFEL and (b) HIPA. We report promising experimental results on both machines, tuning up to 16 parameters subject to 224 constraints.', 'ENTRYTYPE': 'article', 'ID': 'Kirchner2022'}\n",
      "2022-06-01\n",
      "---\n",
      "title: \"Tuning particle accelerators with safety constraints using Bayesian optimization\"\n",
      "\n",
      "permalink: /publication/2022-06-01-Tuning-particle-accelerators-with-safety-constraints-using-Bayesian-optimization\n",
      "date: 2022-06-01\n",
      "venue: 'Phys. Rev. Accel. Beams'\n",
      "url: 'https://link.aps.org/doi/10.1103/PhysRevAccelBeams.25.062802'\n",
      "---\n",
      "\n",
      "Kirschner, Johannes and Mutny, Mojmir and Krause, Andreas and Coello de Portugal, Jaime and Hiller, Nicole and Snuverink, Jochem, Tuning particle accelerators with safety constraints using Bayesian optimization.\", 2022. Phys. Rev. Accel. Beams\n",
      "\n",
      "**Abstract**: Tuning machine parameters of particle accelerators is a repetitive and time-consuming task that is challenging to automate. While many off-the-shelf optimization algorithms are available, in practice their use is limited because most methods do not account for safety-critical constraints in each iteration, such as loss signals or step-size limitations. One notable exception is safe Bayesian optimization, which is a data-driven tuning approach for global optimization with noisy feedback. We propose and evaluate a step-size limited variant of safe Bayesian optimization on two research facilities of the PSI:(a) the SwissFEL and (b) HIPA. We report promising experimental results on both machines, tuning up to 16 parameters subject to 224 constraints.\n",
      "\n",
      "[Full text here](https://link.aps.org/doi/10.1103/PhysRevAccelBeams.25.062802){:target=\"_blank\"}\n",
      "<!--more-->\n",
      "{'year': '2024', 'url': 'https://arxiv.org/abs/2307.13372', 'title': 'Submodular Reinforcement Learning', 'journal': 'ICLR 2024', 'author': \"Prajapat, Manish and Mutn{\\\\'y}, Mojm{\\\\'\\\\i}r and Zeilinger, Melanie N and Krause, Andreas\", 'abstract': 'In reinforcement learning (RL), rewards of states are typically considered additive, and following the Markov assumption, they are of states visited previously. In many important applications, such as coverage control, experiment design and informative path planning, rewards naturally have diminishing returns, i.e., their value decreases in light of similar states visited previously. To tackle this, we propose (SubRL), a paradigm which seeks to optimize more general, non-additive (and history-dependent) rewards modelled via submodular set functions which capture diminishing returns. Unfortunately, in general, even in tabular settings, we show that the resulting optimization problem is hard to approximate. On the other hand, motivated by the success of greedy algorithms in classical submodular optimization, we propose SubPO, a simple policy gradient-based algorithm for SubRL that handles non-additive rewards by greedily maximizing marginal gains. Indeed, under some assumptions on the underlying Markov Decision Process (MDP), SubPO recovers optimal constant factor approximations of submodular bandits. Moreover, we derive a natural policy gradient approach for locally optimizing SubRL instances even in large state- and action- spaces. We showcase the versatility of our approach by applying SubPO to several applications, such as biodiversity monitoring, Bayesian experiment design, informative path planning, and coverage maximization. Our results demonstrate sample efficiency, as well as scalability to high-dimensional state-action spaces.', 'ENTRYTYPE': 'proceedings', 'ID': 'Prajapat2024'}\n",
      "2024-01-01\n",
      "---\n",
      "title: \"Submodular Reinforcement Learning\"\n",
      "\n",
      "permalink: /publication/2024-01-01-Submodular-Reinforcement-Learning\n",
      "date: 2024-01-01\n",
      "venue: 'ICLR 2024'\n",
      "url: 'https://arxiv.org/abs/2307.13372'\n",
      "---\n",
      "\n",
      "Prajapat, Manish and Mutny, Mojmir and Zeilinger, Melanie N and Krause, Andreas, Submodular Reinforcement Learning.\", 2024. ICLR 2024\n",
      "\n",
      "**Abstract**: In reinforcement learning (RL), rewards of states are typically considered additive, and following the Markov assumption, they are of states visited previously. In many important applications, such as coverage control, experiment design and informative path planning, rewards naturally have diminishing returns, i.e., their value decreases in light of similar states visited previously. To tackle this, we propose (SubRL), a paradigm which seeks to optimize more general, non-additive (and history-dependent) rewards modelled via submodular set functions which capture diminishing returns. Unfortunately, in general, even in tabular settings, we show that the resulting optimization problem is hard to approximate. On the other hand, motivated by the success of greedy algorithms in classical submodular optimization, we propose SubPO, a simple policy gradient-based algorithm for SubRL that handles non-additive rewards by greedily maximizing marginal gains. Indeed, under some assumptions on the underlying Markov Decision Process (MDP), SubPO recovers optimal constant factor approximations of submodular bandits. Moreover, we derive a natural policy gradient approach for locally optimizing SubRL instances even in large state- and action- spaces. We showcase the versatility of our approach by applying SubPO to several applications, such as biodiversity monitoring, Bayesian experiment design, informative path planning, and coverage maximization. Our results demonstrate sample efficiency, as well as scalability to high-dimensional state-action spaces.\n",
      "\n",
      "[Full text here](https://arxiv.org/abs/2307.13372){:target=\"_blank\"}\n",
      "<!--more-->\n",
      "{'year': '2023', 'url': 'https://arxiv.org/abs/2311.04402', 'title': 'Likelihood Ratio Confidence Sets for Sequential Decision Making', 'journal': 'NeurIPS 2023', 'booktitle': 'Proc. Neural Information Processing Systems (NeurIPS)', 'author': \"Emmenegger*, Nicolas and Mutn{\\\\'y}*, Mojm{\\\\'\\\\i}r and Krause, Andreas\", 'abstract': 'Certifiable, adaptive uncertainty estimates for unknown quantities are an essential ingredient of sequential decision-making algorithms. Standard approaches rely on problem-dependent concentration results and are limited to a specific combination of parameterization, noise family, and estimator. In this paper, we revisit the likelihood-based inference principle and propose to use\\\\emph {likelihood ratios} to construct\\\\emph {any-time valid} confidence sequences without requiring specialized treatment in each application scenario. Our method is especially suitable for problems with well-specified likelihoods, and the resulting sets always maintain the prescribed coverage in a model-agnostic manner. The size of the sets depends on a choice of estimator sequence in the likelihood ratio. We discuss how to provably choose the best sequence of estimators and shed light on connections to online convex optimization with algorithms such as Follow-the-Regularized-Leader. To counteract the initially large bias of the estimators, we propose a reweighting scheme that also opens up deployment in non-parametric settings such as RKHS function classes. We provide a\\\\emph {non-asymptotic} analysis of the likelihood ratio confidence sets size for generalized linear models, using insights from convex duality and online learning. We showcase the practical strength of our method on generalized linear bandit problems, survival analysis, and bandits with various additive noise distributions.', 'ENTRYTYPE': 'inproceedings', 'ID': 'Emmenegger2023'}\n",
      "2023-01-01\n",
      "---\n",
      "title: \"Likelihood Ratio Confidence Sets for Sequential Decision Making\"\n",
      "\n",
      "permalink: /publication/2023-01-01-Likelihood-Ratio-Confidence-Sets-for-Sequential-Decision-Making\n",
      "date: 2023-01-01\n",
      "venue: 'Proc. Neural Information Processing Systems (NeurIPS)'\n",
      "url: 'https://arxiv.org/abs/2311.04402'\n",
      "---\n",
      "\n",
      "Emmenegger, Nicolas and Mutny, Mojmir and Krause, Andreas, Likelihood Ratio Confidence Sets for Sequential Decision Making.\", 2023. Proc. Neural Information Processing Systems (NeurIPS)\n",
      "\n",
      "**Abstract**: Certifiable, adaptive uncertainty estimates for unknown quantities are an essential ingredient of sequential decision-making algorithms. Standard approaches rely on problem-dependent concentration results and are limited to a specific combination of parameterization, noise family, and estimator. In this paper, we revisit the likelihood-based inference principle and propose to use\\emph {likelihood ratios} to construct\\emph {any-time valid} confidence sequences without requiring specialized treatment in each application scenario. Our method is especially suitable for problems with well-specified likelihoods, and the resulting sets always maintain the prescribed coverage in a model-agnostic manner. The size of the sets depends on a choice of estimator sequence in the likelihood ratio. We discuss how to provably choose the best sequence of estimators and shed light on connections to online convex optimization with algorithms such as Follow-the-Regularized-Leader. To counteract the initially large bias of the estimators, we propose a reweighting scheme that also opens up deployment in non-parametric settings such as RKHS function classes. We provide a\\emph {non-asymptotic} analysis of the likelihood ratio confidence sets size for generalized linear models, using insights from convex duality and online learning. We showcase the practical strength of our method on generalized linear bandit problems, survival analysis, and bandits with various additive noise distributions.\n",
      "\n",
      "[Full text here](https://arxiv.org/abs/2311.04402){:target=\"_blank\"}\n",
      "<!--more-->\n",
      "{'year': '2024', 'url': 'https://www.biorxiv.org/content/10.1101/2024.02.06.579157v1.full.pdf', 'type': 'preprint', 'title': 'Enhanced Sequence-Activity Mapping and Evolution of Artificial Metalloenzymes by Active Learning', 'author': \"Vornholt*, Tobias and Mutn{\\\\'y}*, Mojm{\\\\'\\\\i}r and Schmidt, Gregor and Schellhaas, Christian and Tachibana, Ryo and Panke, Sven and Ward, Thomas R. and Krause, Andreas and Jeschek, Markus\", 'abstract': 'Tailored enzymes hold great potential to accelerate the transition to a sustainable bioeconomy. Yet, enzyme engineering remains challenging as it relies largely on serendipity and is, therefore, highly laborious and prone to failure. The efficiency and success rates of engineering campaigns may be improved substantially by applying machine learning to construct a comprehensive representation of the sequence-activity landscape from small sets of experimental data. However, it often proves challenging to reliably model a large protein sequence space while keeping the experimental effort tractable. To address this challenge, we present an integrated pipeline combining large-scale screening with active machine learning and model-guided library design. We applied this strategy to efficiently engineer an artificial metalloenzyme (ArM) catalysing a new-to-nature hydroamination reaction. By combining lab automation and next-generation sequencing, we acquired sequence-activity data for several thousand ArM variants. We then used Gaussian process regression to model the activity landscape and guide further screening rounds according to user-defined objectives. Crucial characteristics of our enhanced enzyme engineering pipeline include i) the cost-effective generation of information-rich experimental data sets, ii) the integration of an explorative round to improve the performance of the model, as well as iii) the consideration of experimental noise during modelling. Our approach led to an order-of-magnitude boost in the hit rate of screening while making efficient use of experimental resources. Smart search strategies like this should find broad utility in enzyme engineering and accelerate the development of novel biocatalysts.', 'ENTRYTYPE': 'misc', 'ID': 'Vornholt2024'}\n",
      "2024-01-01\n",
      "---\n",
      "title: \"Enhanced Sequence-Activity Mapping and Evolution of Artificial Metalloenzymes by Active Learning\"\n",
      "\n",
      "permalink: /publication/2024-01-01-Enhanced-Sequence-Activity-Mapping-and-Evolution-of-Artificial-Metalloenzymes-by-Active-Learning\n",
      "date: 2024-01-01\n",
      "venue: 'preprint'\n",
      "url: 'https://www.biorxiv.org/content/10.1101/2024.02.06.579157v1.full.pdf'\n",
      "---\n",
      "\n",
      "Vornholt, Tobias and Mutny, Mojmir and Schmidt, Gregor and Schellhaas, Christian and Tachibana, Ryo and Panke, Sven and Ward, Thomas R and Krause, Andreas and Jeschek, Markus, Enhanced Sequence-Activity Mapping and Evolution of Artificial Metalloenzymes by Active Learning.\", 2024. preprint\n",
      "\n",
      "**Abstract**: Tailored enzymes hold great potential to accelerate the transition to a sustainable bioeconomy. Yet, enzyme engineering remains challenging as it relies largely on serendipity and is, therefore, highly laborious and prone to failure. The efficiency and success rates of engineering campaigns may be improved substantially by applying machine learning to construct a comprehensive representation of the sequence-activity landscape from small sets of experimental data. However, it often proves challenging to reliably model a large protein sequence space while keeping the experimental effort tractable. To address this challenge, we present an integrated pipeline combining large-scale screening with active machine learning and model-guided library design. We applied this strategy to efficiently engineer an artificial metalloenzyme (ArM) catalysing a new-to-nature hydroamination reaction. By combining lab automation and next-generation sequencing, we acquired sequence-activity data for several thousand ArM variants. We then used Gaussian process regression to model the activity landscape and guide further screening rounds according to user-defined objectives. Crucial characteristics of our enhanced enzyme engineering pipeline include i) the cost-effective generation of information-rich experimental data sets, ii) the integration of an explorative round to improve the performance of the model, as well as iii) the consideration of experimental noise during modelling. Our approach led to an order-of-magnitude boost in the hit rate of screening while making efficient use of experimental resources. Smart search strategies like this should find broad utility in enzyme engineering and accelerate the development of novel biocatalysts.\n",
      "\n",
      "[Full text here](https://www.biorxiv.org/content/10.1101/2024.02.06.579157v1.full.pdf){:target=\"_blank\"}\n",
      "<!--more-->\n",
      "{'year': '2024', 'title': 'Sequential Experimental Design and Optimization with Structural Assumptions: Additivity and Subspaces', 'journal': '(in preparation for JMLR)', 'author': \"Mutn{\\\\'y}, Mojm{\\\\'\\\\i}r and Krause, Andreas\", 'abstract': 'Experiment design in high-dimensional problems is an important practical problem in many fields of science. Without further structural assumptions, the experiment design algorithms based on reproducing kernel hilbert spaces with classical kernels suffer from curse of dimensionality. In this work we explore additional structural assumptions of additive structure or variability in low dimensional linear subspace. We present the prior works in unified framework and analyze the projection pursuit regression models in the context of experiment design, which strictly generalize additive models. We combine them with potentially non-linear effective dimension via manifold projection pursuit regression model. We contrast to other methods developed and we address practical issues such as acquisition function optimization.', 'ENTRYTYPE': 'article', 'ID': 'Mutny2024'}\n",
      "2024-01-01\n",
      "---\n",
      "title: \"Sequential Experimental Design and Optimization with Structural Assumptions: Additivity and Subspaces\"\n",
      "\n",
      "permalink: /publication/2024-01-01-Sequential-Experimental-Design-and-Optimization-with-Structural-Assumptions-Additivity-and-Subspaces\n",
      "date: 2024-01-01\n",
      "venue: '(in preparation for JMLR)'\n",
      "---\n",
      "\n",
      "Mutny, Mojmir and Krause, Andreas, Sequential Experimental Design and Optimization with Structural Assumptions: Additivity and Subspaces.\", 2024. (in preparation for JMLR)\n",
      "\n",
      "**Abstract**: Experiment design in high-dimensional problems is an important practical problem in many fields of science. Without further structural assumptions, the experiment design algorithms based on reproducing kernel hilbert spaces with classical kernels suffer from curse of dimensionality. In this work we explore additional structural assumptions of additive structure or variability in low dimensional linear subspace. We present the prior works in unified framework and analyze the projection pursuit regression models in the context of experiment design, which strictly generalize additive models. We combine them with potentially non-linear effective dimension via manifold projection pursuit regression model. We contrast to other methods developed and we address practical issues such as acquisition function optimization.\n",
      "\n",
      "Use [Google Scholar](https://scholar.google.com/scholar?q=Sequential+Experimental+Design+and+Optimization+with+Structural+Assumptions:+Additivity+and+Subspaces){:target=\"_blank\"} for full citation<!--more-->\n",
      "{'year': '2023', 'url': 'https://mojmirmutny.github.io/publication/ReALML_workshop_Protein_Design_and_Game_Theory.pdf', 'title': 'Optimistic Games for Combinatorial Bayesian Optimization with Applications to Protein Design', 'booktitle': '3rd ReALML Workshop at NeurIPS 2023', 'author': \"Bal, Melis {\\\\.I}layda and Sessa, Pier Giuseppe and Mutn{\\\\'y}, Mojm{\\\\'\\\\i}r and Krause, Andreas\", 'abstract': 'Bayesian optimization (BO) is a powerful framework to optimize black box expensive-to-evaluate functions via sequential interactions. In several important problems (e.g. drug discovery, circuit design, neural architecture search, etc.), though, such functions are defined over $\\\\textit{combinatorial and unstructured}$ spaces. This makes existing BO algorithms not feasible due to the intractable maximization of the acquisition function to find informative evaluation points. To address this issue, we propose $\\\\textbf{GameOpt}$, a novel game-theoretical approach to combinatorial BO. $\\\\textbf{GameOpt}$ establishes a cooperative game between the different optimization variables and computes informative points to be game $\\\\textit{equilibria}$ of the acquisition function. These are stable configurations from which no variable has an incentive to deviate -- analogous to local optima in continuous domains. Crucially, this allows us to efficiently break down the complexity of the combinatorial domain into individual decision sets, making $\\\\textbf{GameOpt}$ scalable to large combinatorial spaces. We demonstrate the application of $\\\\textbf{GameOpt}$ to the challenging $\\\\textit{protein design}$ problem and validate its performance on two real-world protein datasets. Each protein can take up to $20^{X}$ possible configurations, where $X$ is the length of a protein, making standard BO methods unusable. Instead, our approach iteratively selects informative protein configurations and very quickly discovers highly active protein variants compared to other baselines.', 'ENTRYTYPE': 'article', 'ID': 'Bal2023'}\n",
      "2023-01-01\n",
      "---\n",
      "title: \"Optimistic Games for Combinatorial Bayesian Optimization with Applications to Protein Design\"\n",
      "\n",
      "permalink: /publication/2023-01-01-Optimistic-Games-for-Combinatorial-Bayesian-Optimization-with-Applications-to-Protein-Design\n",
      "date: 2023-01-01\n",
      "venue: '3rd ReALML Workshop at NeurIPS 2023'\n",
      "url: 'https://mojmirmutny.github.io/publication/ReALML_workshop_Protein_Design_and_Game_Theory.pdf'\n",
      "---\n",
      "\n",
      "Bal, Melis Ilayda and Sessa, Pier Giuseppe and Mutny, Mojmir and Krause, Andreas, Optimistic Games for Combinatorial Bayesian Optimization with Applications to Protein Design.\", 2023. 3rd ReALML Workshop at NeurIPS 2023\n",
      "\n",
      "**Abstract**: Bayesian optimization (BO) is a powerful framework to optimize black box expensive-to-evaluate functions via sequential interactions. In several important problems (e.g. drug discovery, circuit design, neural architecture search, etc.), though, such functions are defined over $\\textit{combinatorial and unstructured}$ spaces. This makes existing BO algorithms not feasible due to the intractable maximization of the acquisition function to find informative evaluation points. To address this issue, we propose $\\textbf{GameOpt}$, a novel game-theoretical approach to combinatorial BO. $\\textbf{GameOpt}$ establishes a cooperative game between the different optimization variables and computes informative points to be game $\\textit{equilibria}$ of the acquisition function. These are stable configurations from which no variable has an incentive to deviate -- analogous to local optima in continuous domains. Crucially, this allows us to efficiently break down the complexity of the combinatorial domain into individual decision sets, making $\\textbf{GameOpt}$ scalable to large combinatorial spaces. We demonstrate the application of $\\textbf{GameOpt}$ to the challenging $\\textit{protein design}$ problem and validate its performance on two real-world protein datasets. Each protein can take up to $20^{X}$ possible configurations, where $X$ is the length of a protein, making standard BO methods unusable. Instead, our approach iteratively selects informative protein configurations and very quickly discovers highly active protein variants compared to other baselines.\n",
      "\n",
      "[Full text here](https://mojmirmutny.github.io/publication/ReALML_workshop_Protein_Design_and_Game_Theory.pdf){:target=\"_blank\"}\n",
      "<!--more-->\n",
      "{'year': '2024', 'url': 'https://arxiv.org/abs/2402.08406', 'type': 'preprint', 'title': 'Transition Constrained Bayesian Optimization via Markov Decision Processes', 'primaryclass': 'cs.LG', 'journal': 'arXiv:2402.08406', 'eprint': '2402.08406', 'author': \"Folch, Jose Pablo and Tsay, Calvin and Lee, Robert M and Shafei, Behrang and Ormaniec, Weronika and Krause, Andreas and van der Wilk, Mark and Misener, Ruth and Mutn{\\\\'y}, Mojm{\\\\'\\\\i}r\", 'archiveprefix': 'arXiv', 'abstract': 'Bayesian optimization is a methodology to optimize black-box functions. Traditionally, it focuses on the setting where you can arbitrarily query the search space. However, many real-life problems do not offer this flexibility; in particular, the search space of the next query may depend on previous ones. Example challenges arise in the physical sciences in the form of local movement constraints, required monotonicity in certain variables, and transitions influencing the accuracy of measurements. Altogether, such transition constraints necessitate a form of planning. This work extends Bayesian optimization via the framework of Markov Decision Processes, iteratively solving a tractable linearization of our objective using reinforcement learning to obtain a policy that plans ahead over long horizons. The resulting policy is potentially history-dependent and non-Markovian. We showcase applications in chemical reactor optimization, informative path planning, machine calibration, and other synthetic examples.', 'ENTRYTYPE': 'misc', 'ID': 'Folch2024transition'}\n",
      "2024-01-01\n",
      "---\n",
      "title: \"Transition Constrained Bayesian Optimization via Markov Decision Processes\"\n",
      "\n",
      "permalink: /publication/2024-01-01-Transition-Constrained-Bayesian-Optimization-via-Markov-Decision-Processes\n",
      "date: 2024-01-01\n",
      "venue: 'arXiv:2402.08406'\n",
      "url: 'https://arxiv.org/abs/2402.08406'\n",
      "---\n",
      "\n",
      "Folch, Jose Pablo and Tsay, Calvin and Lee, Robert M and Shafei, Behrang and Ormaniec, Weronika and Krause, Andreas and van der Wilk, Mark and Misener, Ruth and Mutny, Mojmir, Transition Constrained Bayesian Optimization via Markov Decision Processes.\", 2024. arXiv:2402.08406\n",
      "\n",
      "**Abstract**: Bayesian optimization is a methodology to optimize black-box functions. Traditionally, it focuses on the setting where you can arbitrarily query the search space. However, many real-life problems do not offer this flexibility; in particular, the search space of the next query may depend on previous ones. Example challenges arise in the physical sciences in the form of local movement constraints, required monotonicity in certain variables, and transitions influencing the accuracy of measurements. Altogether, such transition constraints necessitate a form of planning. This work extends Bayesian optimization via the framework of Markov Decision Processes, iteratively solving a tractable linearization of our objective using reinforcement learning to obtain a policy that plans ahead over long horizons. The resulting policy is potentially history-dependent and non-Markovian. We showcase applications in chemical reactor optimization, informative path planning, machine calibration, and other synthetic examples.\n",
      "\n",
      "[Full text here](https://arxiv.org/abs/2402.08406){:target=\"_blank\"}\n",
      "<!--more-->\n",
      "{'year': '2024', 'type': 'phd', 'title': 'Modern Adaptive Experiment Design: Machine Learning Perspective', 'month': 'April', 'howpublished': 'https://www.research-collection.ethz.ch/handle/20.500.11850/669541', 'author': \"Mutn{\\\\'y}, Mojm{\\\\'\\\\i}r\", 'abstract': \"A key challenge in science and engineering is to design experiments to learn about some unknown quantity of interest. Optimal experimental design is a branch of statistics addressing the most informative allocation of experiments in order to infer an unknown quantity of interest. In this thesis, we fundamentally revisit and extend the methods and approaches of optimal design of experiments when our unknown quantity is a member of a reproducing kernel Hilbert space (RKHS). Estimation in RKHS is a versatile, yet sample-efficient non-parametric statistical method that allows us to capture non-linear natural phenomena using the concept of a similarity also known as the kernel. The process to set up an statistical experiment design pipeline begins by establishing a mathematical model and defining the experiment's goal as a utility. We consider the available experiments and adapt to uncertain outcomes. This thesis specifically tackles adaptive experiment design, where previous experiment outcomes inform future utility design and selection strategies. We first outline a general methodology for adaptive experiment design, addressing uncertainty and combinatorial issues through relaxation techniques. We introduce a master algorithm and its linearized form based on the Frank-Wolfe algorithm, applicable to general experimental design problems. This algorithm is demonstrated in applications involving various utilities, including reward minimization and information gathering. Subsequent sections delve into the impact of structural assumptions about the unknown quantity in RKHS, such as additivity and projection pursuit structures. We analyze these models and additionally introduce novel mathematical structures in RKHS, aiming to enhance the richness and resource efficiency of experiment design. Adaptive design requires statistical estimation and confidence estimates for the unknown quantity in the presence of randomness. We thoroughly analyze this issue from a worst-case perspective, developing confidence sets for probability distributions from parametrized families. Departing from the worst-case perspective, we provide likelihood-based confidence sets for experiments with well-specified likelihood models that provide significant improvement over the worst-case analysis. Additionally, we explore complex experiment design scenarios, where the design involves executing a policy in a sequence of steps generating trajectories. We provide a tractable reformulation of this problem using Markov chains, providing examples and modifications to traditional experimental design methods. Lastly, we demonstrate the application and versatility of modern adaptive experiment design in various domains, including enzyme optimization, adaptive Poisson sensing for spatio-temporal events, learning differential equations, and classical problems related to inferring functionals of unknown quantities.\", 'ENTRYTYPE': 'phdthesis', 'ID': 'Mutny2024t'}\n",
      "2024-04-01\n",
      "---\n",
      "title: \"Modern Adaptive Experiment Design: Machine Learning Perspective\"\n",
      "\n",
      "permalink: /publication/2024-04-01-Modern-Adaptive-Experiment-Design-Machine-Learning-Perspective\n",
      "date: 2024-04-01\n",
      "venue: 'PhD Thesis, ETH Zurich'\n",
      "---\n",
      "\n",
      "Mutny, Mojmir, Modern Adaptive Experiment Design: Machine Learning Perspective.\", 2024. PhD Thesis, ETH Zurich\n",
      "\n",
      "**Abstract**: A key challenge in science and engineering is to design experiments to learn about some unknown quantity of interest. Optimal experimental design is a branch of statistics addressing the most informative allocation of experiments in order to infer an unknown quantity of interest. In this thesis, we fundamentally revisit and extend the methods and approaches of optimal design of experiments when our unknown quantity is a member of a reproducing kernel Hilbert space (RKHS). Estimation in RKHS is a versatile, yet sample-efficient non-parametric statistical method that allows us to capture non-linear natural phenomena using the concept of a similarity also known as the kernel. The process to set up an statistical experiment design pipeline begins by establishing a mathematical model and defining the experiment's goal as a utility. We consider the available experiments and adapt to uncertain outcomes. This thesis specifically tackles adaptive experiment design, where previous experiment outcomes inform future utility design and selection strategies. We first outline a general methodology for adaptive experiment design, addressing uncertainty and combinatorial issues through relaxation techniques. We introduce a master algorithm and its linearized form based on the Frank-Wolfe algorithm, applicable to general experimental design problems. This algorithm is demonstrated in applications involving various utilities, including reward minimization and information gathering. Subsequent sections delve into the impact of structural assumptions about the unknown quantity in RKHS, such as additivity and projection pursuit structures. We analyze these models and additionally introduce novel mathematical structures in RKHS, aiming to enhance the richness and resource efficiency of experiment design. Adaptive design requires statistical estimation and confidence estimates for the unknown quantity in the presence of randomness. We thoroughly analyze this issue from a worst-case perspective, developing confidence sets for probability distributions from parametrized families. Departing from the worst-case perspective, we provide likelihood-based confidence sets for experiments with well-specified likelihood models that provide significant improvement over the worst-case analysis. Additionally, we explore complex experiment design scenarios, where the design involves executing a policy in a sequence of steps generating trajectories. We provide a tractable reformulation of this problem using Markov chains, providing examples and modifications to traditional experimental design methods. Lastly, we demonstrate the application and versatility of modern adaptive experiment design in various domains, including enzyme optimization, adaptive Poisson sensing for spatio-temporal events, learning differential equations, and classical problems related to inferring functionals of unknown quantities.\n",
      "\n",
      "Use [Google Scholar](https://scholar.google.com/scholar?q=Modern+Adaptive+Experiment+Design:+Machine+Learning+Perspective){:target=\"_blank\"} for full citation<!--more-->\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#loop through the individual references in a given bibtex file\n",
    "for b in bibdata.values():\n",
    "    #reset default date\n",
    "    pub_year = \"1900\"\n",
    "    pub_month = \"01\"\n",
    "    pub_day = \"01\"\n",
    "    \n",
    "    #b = bibdata.values[bib_id].fields\n",
    "    #print (b)\n",
    "    print (b)\n",
    "    try:\n",
    "        pub_year = f'{b[\"year\"]}'\n",
    "\n",
    "        # #todo: this hack for month and day needs some cleanup\n",
    "        if \"month\" in b.keys(): \n",
    "            if(len(b[\"month\"])<3):\n",
    "                pub_month = \"0\"+b[\"month\"]\n",
    "                pub_month = pub_month[-2:]\n",
    "            elif(b[\"month\"] not in range(12)):\n",
    "                tmnth = strptime(b[\"month\"][:3],'%b').tm_mon   \n",
    "                pub_month = \"{:02d}\".format(tmnth) \n",
    "            else:\n",
    "                pub_month = str(b[\"month\"])\n",
    "        if \"day\" in b.keys(): \n",
    "            pub_day = str(b[\"day\"])\n",
    "\n",
    "        pub_date = pub_year+\"-\"+pub_month+\"-\"+pub_day\n",
    "        print (pub_date)\n",
    "        #strip out {} as needed (some bibtex entries that maintain formatting)\n",
    "        clean_title = b[\"title\"].replace(\"{\", \"\").replace(\"}\",\"\").replace(\"\\\\\",\"\").replace(\" \",\"-\")    \n",
    "\n",
    "        url_slug = re.sub(\"\\\\[.*\\\\]|[^a-zA-Z0-9_-]\", \"\", clean_title)\n",
    "        url_slug = url_slug.replace(\"--\",\"-\")\n",
    "\n",
    "        md_filename = (str(pub_date) + \"-\" + url_slug + \".md\").replace(\"--\",\"-\")\n",
    "        html_filename = (str(pub_date) + \"-\" + url_slug).replace(\"--\",\"-\")\n",
    "\n",
    "        #Build Citation from text\n",
    "        citation = \"\"\n",
    "        \n",
    "        # for author in b[\"author\"]:\n",
    "        #     #print (author.first_names[0], author.last_names[0])\n",
    "        #     #citation += f\" {author.first_names[0]} {author.last_names[0]}, \"\n",
    "        #     citation =+str(author) + \", \"\n",
    "        #     #citation += author.first_names[0]+\" \"+author.last_names[0]+\", \"\n",
    "\n",
    "            #citation title\n",
    "        citation = b[\"author\"]\n",
    "        citation = filter_alphabetic(citation) + \", \" + html_escape(b[\"title\"].replace(\"{\", \"\").replace(\"}\",\"\").replace(\"\\\\\",\"\")) + \".\\\"\"\n",
    "\n",
    "        #add venue logic depending on citation type\n",
    "        if 'booktitle' in b.keys():\n",
    "            venue =b['booktitle']\n",
    "        elif 'journal' in b.keys():\n",
    "            venue =b['journal']\n",
    "        elif b['type']=='preprint':\n",
    "            venue = 'preprint'\n",
    "        elif b['type']=='phd':\n",
    "            venue = 'PhD Thesis, ETH Zurich'\n",
    "        else:\n",
    "            venue = ''\n",
    "        #venue = ''\n",
    "        #print (b)\n",
    "        citation = citation + \", \" + pub_year + \". \" + venue \n",
    "       \n",
    "        ## YAML variables\n",
    "        md = \"---\\ntitle: \\\"\"   + html_escape(b[\"title\"].replace(\"{\", \"\").replace(\"}\",\"\").replace(\"\\\\\",\"\")) + '\"\\n'\n",
    "        \n",
    "        #md += \"\"\"collection: \"\"\" +  \"publication\"\n",
    "\n",
    "        md += \"\"\"\\npermalink: \"\"\" +\"/publication/\"  + html_filename\n",
    "        \n",
    "        note = False\n",
    "        # if \"note\" in b.keys():\n",
    "        #     if len(str(b[\"note\"])) > 5:\n",
    "        #         md += \"\\nexcerpt: '\" + html_escape(b[\"note\"]) + \"'\"\n",
    "        #         note = True\n",
    "\n",
    "        md += \"\\ndate: \" + str(pub_date) \n",
    "        md += \"\\nvenue: '\" + html_escape(venue) + \"'\"\n",
    "        \n",
    "        url = False\n",
    "        if \"url\" in b.keys():\n",
    "            if len(str(b[\"url\"])) > 5:\n",
    "                md += \"\\nurl: '\" + b[\"url\"] + \"'\"\n",
    "                url = True\n",
    "\n",
    "        #md += \"\\ncitation: '\" + html_escape(citation) + \"'\"\n",
    "\n",
    "        md += \"\\n---\\n\"\n",
    "        md+=\"\\n\"+citation\n",
    "\n",
    "        if 'abstract' in b.keys():\n",
    "            md += \"\\n\\n**Abstract**: \" + b['abstract']\n",
    "        \n",
    "\n",
    "        if url:\n",
    "            md += \"\\n\\n[Full text here](\" + b[\"url\"] + \"){:target=\\\"_blank\\\"}\\n\" \n",
    "        else:\n",
    "            md += \"\\n\\nUse [Google Scholar](https://scholar.google.com/scholar?q=\"+html.escape(clean_title.replace(\"-\",\"+\"))+\"){:target=\\\"_blank\\\"} for full citation\"\n",
    "\n",
    "\n",
    "        md +=\"<!--more-->\"\n",
    "        md_filename = os.path.basename(md_filename)\n",
    "        print (md)\n",
    "        with open(\"../_publications/\" + md_filename, 'w', encoding=\"utf-8\") as f:\n",
    "            f.write(md)\n",
    "        #print(f'SUCESSFULLY PARSED {bib_id}: \\\"', b[\"title\"][:60],\"...\"*(len(b['title'])>60),\"\\\"\")\n",
    "    # field may not exist for a reference\n",
    "    except KeyError as e:\n",
    "        print(f'WARNING Missing Expected Field {e} from entry {bib_id}: \\\"', b[\"title\"][:30],\"...\"*(len(b['title'])>30),\"\\\"\")\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
